name: s3cmd
description: a tool for managing objects in Amazon S3 storage
usage: 's3cmd [options] COMMAND [parameters]'
options:
  - names:
      - -h
      - --help
    argument: ""
    description: show this help message and exit
  - names:
      - --configure
    argument: ""
    description: Invoke interactive (re)configuration tool. Optionally use as '--configure s3://some-bucket' to test access to a specific bucket instead of attempting to list them all.
  - names:
      - -c
      - --config
    argument: FILE
    description: Config file name. Defaults to $HOME/.s3cfg
  - names:
      - --dump-config
    argument: ""
    description: Dump current configuration after parsing config files and command line options and exit.
  - names:
      - --access_key
    argument: ACCESS_KEY
    description: AWS Access Key
  - names:
      - --secret_key
    argument: SECRET_KEY
    description: AWS Secret Key
  - names:
      - --access_token
    argument: ACCESS_TOKEN
    description: AWS Access Token
  - names:
      - -n
      - --dry-run
    argument: ""
    description: Only show what should be uploaded or downloaded but don't actually do it. May still perform S3 requests to get bucket listings and other information though (only for file transfer commands)
  - names:
      - -s
      - --ssl
    argument: ""
    description: Use HTTPS connection when communicating with S3. (default)
  - names:
      - --no-ssl
    argument: ""
    description: Don't use HTTPS.
  - names:
      - -e
      - --encrypt
    argument: ""
    description: Encrypt files before uploading to S3.
  - names:
      - --no-encrypt
    argument: ""
    description: Don't encrypt files.
  - names:
      - -f
      - --force
    argument: ""
    description: Force overwrite and other dangerous operations.
  - names:
      - --continue
    argument: ""
    description: Continue getting a partially downloaded file (only for [get] command).
  - names:
      - --continue-put
    argument: ""
    description: 'Continue uploading partially uploaded files or multipart upload parts. Restarts parts/files that don''t have matching size and md5. Skips files/parts that do. Note: md5sum checks are not always sufficient to check (part) file equality. Enable this at your own risk.'
  - names:
      - --upload-id
    argument: UPLOAD_ID
    description: UploadId for Multipart Upload, in case you want continue an existing upload (equivalent to --continue-put) and there are multiple partial uploads. Use s3cmd multipart [URI] to see what UploadIds are associated with the given URI.
  - names:
      - --skip-existing
    argument: ""
    description: Skip over files that exist at the destination (only for [get] and [sync] commands).
  - names:
      - -r
      - --recursive
    argument: ""
    description: Recursive upload, download or removal.
  - names:
      - --check-md5
    argument: ""
    description: Check MD5 sums when comparing files for [sync]. (default)
  - names:
      - --no-check-md5
    argument: ""
    description: Do not check MD5 sums when comparing files for [sync]. Only size will be compared. May significantly speed up transfer but may also miss some changed files.
  - names:
      - -P
      - --acl-public
    argument: ""
    description: Store objects with ACL allowing read for anyone.
  - names:
      - --acl-private
    argument: ""
    description: Store objects with default ACL allowing access for you only.
  - names:
      - --acl-revoke
    argument: PERMISSION:USER_CANONICAL_ID
    description: 'Revoke stated permission for a given amazon user. Permission is one of: read, write, read_acp, write_acp, full_control, all'
  - names:
      - -D
      - --restore-days
    argument: NUM
    description: Number of days to keep restored file available (only for 'restore' command). Default is 1 day.
  - names:
      - --restore-priority
    argument: RESTORE_PRIORITY
    description: 'Priority for restoring files from S3 Glacier (only for ''restore'' command). Choices available: bulk, standard, expedited'
  - names:
      - --delete-removed
    argument: ""
    description: Delete destination objects with no corresponding source file [sync]
  - names:
      - --no-delete-removed
    argument: ""
    description: Don't delete destination objects [sync]
  - names:
      - --delete-after
    argument: ""
    description: Perform deletes AFTER new uploads when delete-removed is enabled [sync]
  - names:
      - --delay-updates
    argument: ""
    description: '*OBSOLETE* Put all updated files into place at end [sync]'
  - names:
      - --max-delete
    argument: NUM
    description: Do not delete more than NUM files. [del] and [sync]
  - names:
      - --limit
    argument: NUM
    description: Limit number of objects returned in the response body (only for [ls] and [la] commands)
  - names:
      - --add-destination
    argument: ADDITIONAL_DESTINATIONS
    description: Additional destination for parallel uploads, in addition to last arg. May be repeated.
  - names:
      - --delete-after-fetch
    argument: ""
    description: Delete remote objects after fetching to local file (only for [get] and [sync] commands).
  - names:
      - -p
      - --preserve
    argument: ""
    description: Preserve filesystem attributes (mode, ownership, timestamps). Default for [sync] command.
  - names:
      - --no-preserve
    argument: ""
    description: Don't store FS attributes
  - names:
      - --exclude
    argument: GLOB
    description: Filenames and paths matching GLOB will be excluded from sync
  - names:
      - --exclude-from
    argument: FILE
    description: Read --exclude GLOBs from FILE
  - names:
      - --rexclude
    argument: REGEXP
    description: Filenames and paths matching REGEXP (regular expression) will be excluded from sync
  - names:
      - --rexclude-from
    argument: FILE
    description: Read --rexclude REGEXPs from FILE
  - names:
      - --include
    argument: GLOB
    description: Filenames and paths matching GLOB will be included even if previously excluded by one of --(r)exclude(-from) patterns
  - names:
      - --include-from
    argument: FILE
    description: Read --include GLOBs from FILE
  - names:
      - --rinclude
    argument: REGEXP
    description: Same as --include but uses REGEXP (regular expression) instead of GLOB
  - names:
      - --rinclude-from
    argument: FILE
    description: Read --rinclude REGEXPs from FILE
  - names:
      - --files-from
    argument: FILE
    description: Read list of source-file names from FILE. Use - to read from stdin.
  - names:
      - --region
      - --bucket-location
    argument: REGION
    description: 'Region to create bucket in. As of now the regions are: us-east-1, us-west-1, us-west-2, eu-west-1, eu-central-1, ap-northeast-1, ap-southeast-1, ap-southeast-2, sa-east-1'
  - names:
      - --host
    argument: HOSTNAME
    description: 'HOSTNAME:PORT for S3 endpoint (default: s3.amazonaws.com, alternatives such as s3-eu-west-1.amazonaws.com). You should also set --host-bucket.'
  - names:
      - --host-bucket
    argument: HOST_BUCKET
    description: 'DNS-style bucket+hostname:port template for accessing a bucket (default: %(bucket)s.s3.amazonaws.com)'
  - names:
      - --reduced-redundancy
      - --rr
    argument: ""
    description: Store object with 'Reduced redundancy'. Lower per-GB price. [put, cp, mv]
  - names:
      - --no-reduced-redundancy
      - --no-rr
    argument: ""
    description: Store object without 'Reduced redundancy'. Higher per-GB price. [put, cp, mv]
  - names:
      - --storage-class
    argument: CLASS
    description: Store object with specified CLASS (STANDARD, STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING, GLACIER or DEEP_ARCHIVE). [put, cp, mv]
  - names:
      - --access-logging-target-prefix
    argument: LOG_TARGET_PREFIX
    description: Target prefix for access logs (S3 URI) (for [cfmodify] and [accesslog] commands)
  - names:
      - --no-access-logging
    argument: ""
    description: Disable access logging (for [cfmodify] and [accesslog] commands)
  - names:
      - --default-mime-type
    argument: DEFAULT_MIME_TYPE
    description: Default MIME-type for stored objects. Application default is binary/octet-stream.
  - names:
      - -M
      - --guess-mime-type
    argument: ""
    description: Guess MIME-type of files by their extension or mime magic. Fall back to default MIME-Type as specified by --default-mime-type option
  - names:
      - --no-guess-mime-type
    argument: ""
    description: Don't guess MIME-type and use the default type instead.
  - names:
      - --no-mime-magic
    argument: ""
    description: Don't use mime magic when guessing MIME-type.
  - names:
      - -m
      - --mime-type
    argument: MIME/TYPE
    description: Force MIME-type. Override both --default-mime-type and --guess-mime-type.
  - names:
      - --add-header
    argument: NAME:VALUE
    description: Add a given HTTP header to the upload request. Can be used multiple times. For instance set 'Expires' or 'Cache-Control' headers (or both) using this option.
  - names:
      - --remove-header
    argument: NAME
    description: Remove a given HTTP header. Can be used multiple times. For instance, remove 'Expires' or 'Cache-Control' headers (or both) using this option. [modify]
  - names:
      - --server-side-encryption
    argument: ""
    description: Specifies that server-side encryption will be used when putting objects. [put, sync, cp, modify]
  - names:
      - --server-side-encryption-kms-id
    argument: KMS_KEY
    description: Specifies the key id used for server-side encryption with AWS KMS-Managed Keys (SSE-KMS) when putting objects. [put, sync, cp, modify]
  - names:
      - --encoding
    argument: ENCODING
    description: 'Override autodetected terminal and filesystem encoding (character set). Autodetected: UTF-8'
  - names:
      - --add-encoding-exts
    argument: EXTENSIONs
    description: Add encoding to these comma delimited extensions i.e. (css,js,html) when uploading to S3 )
  - names:
      - --verbatim
    argument: ""
    description: Use the S3 name as given on the command line. No pre-processing, encoding, etc. Use with caution!
  - names:
      - --disable-multipart
    argument: ""
    description: Disable multipart upload on files bigger than --multipart-chunk-size-mb
  - names:
      - --multipart-chunk-size-mb
    argument: SIZE
    description: Size of each chunk of a multipart upload. Files bigger than SIZE are automatically uploaded as multithreaded-multipart, smaller files are uploaded using the traditional method. SIZE is in Mega-Bytes, default chunk size is 15MB, minimum allowed chunk size is 5MB, maximum is 5GB.
  - names:
      - --list-md5
    argument: ""
    description: Include MD5 sums in bucket listings (only for 'ls' command).
  - names:
      - --list-allow-unordered
    argument: ""
    description: Not an AWS standard. Allow the listing results to be returned in unsorted order. This may be faster when listing very large buckets.
  - names:
      - -H
      - --human-readable-sizes
    argument: ""
    description: Print sizes in human readable form (eg 1kB instead of 1234).
  - names:
      - --ws-index
    argument: WEBSITE_INDEX
    description: Name of index-document (only for [ws-create] command)
  - names:
      - --ws-error
    argument: WEBSITE_ERROR
    description: Name of error-document (only for [ws-create] command)
  - names:
      - --expiry-date
    argument: EXPIRY_DATE
    description: Indicates when the expiration rule takes effect. (only for [expire] command)
  - names:
      - --expiry-days
    argument: EXPIRY_DAYS
    description: Indicates the number of days after object creation the expiration rule takes effect. (only for [expire] command)
  - names:
      - --expiry-prefix
    argument: EXPIRY_PREFIX
    description: Identifying one or more objects with the prefix to which the expiration rule applies. (only for [expire] command)
  - names:
      - --progress
    argument: ""
    description: Display progress meter (default on TTY).
  - names:
      - --no-progress
    argument: ""
    description: Don't display progress meter (default on non-TTY).
  - names:
      - --stats
    argument: ""
    description: Give some file-transfer stats.
  - names:
      - --enable
    argument: ""
    description: Enable given CloudFront distribution (only for [cfmodify] command)
  - names:
      - --disable
    argument: ""
    description: Disable given CloudFront distribution (only for [cfmodify] command)
  - names:
      - --cf-invalidate
    argument: ""
    description: Invalidate the uploaded filed in CloudFront. Also see [cfinval] command.
  - names:
      - --cf-invalidate-default-index
    argument: ""
    description: When using Custom Origin and S3 static website, invalidate the default index file.
  - names:
      - --cf-no-invalidate-default-index-root
    argument: ""
    description: When using Custom Origin and S3 static website, don't invalidate the path to the default index file.
  - names:
      - --cf-add-cname
    argument: CNAME
    description: Add given CNAME to a CloudFront distribution (only for [cfcreate] and [cfmodify] commands)
  - names:
      - --cf-remove-cname
    argument: CNAME
    description: Remove given CNAME from a CloudFront distribution (only for [cfmodify] command)
  - names:
      - --cf-comment
    argument: COMMENT
    description: Set COMMENT for a given CloudFront distribution (only for [cfcreate] and [cfmodify] commands)
  - names:
      - --cf-default-root-object
    argument: DEFAULT_ROOT_OBJECT
    description: Set the default root object to return when no object is specified in the URL. Use a relative path, i.e. default/index.html instead of /default/index.html or s3://bucket/default/index.html (only for [cfcreate] and [cfmodify] commands)
  - names:
      - -v
      - --verbose
    argument: ""
    description: Enable verbose output.
  - names:
      - -d
      - --debug
    argument: ""
    description: Enable debug output.
  - names:
      - --version
    argument: ""
    description: Show s3cmd version (2.3.0) and exit.
  - names:
      - -F
      - --follow-symlinks
    argument: ""
    description: Follow symbolic links as if they are regular files
  - names:
      - --cache-file
    argument: FILE
    description: Cache FILE containing local source MD5 values
  - names:
      - -q
      - --quiet
    argument: ""
    description: Silence output on stdout
  - names:
      - --ca-certs
    argument: CA_CERTS_FILE
    description: Path to SSL CA certificate FILE (instead of system default)
  - names:
      - --ssl-cert
    argument: SSL_CLIENT_CERT_FILE
    description: Path to client own SSL certificate CRT_FILE
  - names:
      - --ssl-key
    argument: SSL_CLIENT_KEY_FILE
    description: Path to client own SSL certificate private key KEY_FILE
  - names:
      - --check-certificate
    argument: ""
    description: Check SSL certificate validity
  - names:
      - --no-check-certificate
    argument: ""
    description: Do not check SSL certificate validity
  - names:
      - --check-hostname
    argument: ""
    description: Check SSL certificate hostname validity
  - names:
      - --no-check-hostname
    argument: ""
    description: Do not check SSL certificate hostname validity
  - names:
      - --signature-v2
    argument: ""
    description: Use AWS Signature version 2 instead of newer signature methods. Helpful for S3-like systems that don't have AWS Signature v4 yet.
  - names:
      - --limit-rate
    argument: LIMITRATE
    description: Limit the upload or download speed to amount bytes per second. Amount may be expressed in bytes, kilobytes with the k suffix, or megabytes with the m suffix
  - names:
      - --no-connection-pooling
    argument: ""
    description: Disable connection re-use
  - names:
      - --requester-pays
    argument: ""
    description: Set the REQUESTER PAYS flag for operations
  - names:
      - -l
      - --long-listing
    argument: ""
    description: Produce long listing [ls]
  - names:
      - --stop-on-error
    argument: ""
    description: stop if error in transfer
  - names:
      - --content-disposition
    argument: CONTENT_DISPOSITION
    description: Provide a Content-Disposition for signed URLs, e.g., "inline; filename=myvideo.mp4"
  - names:
      - --content-type
    argument: CONTENT_TYPE
    description: Provide a Content-Type for signed URLs, e.g., "video/mp4"
subcommands:
  - name: mb
    description: Make bucket
    usage: 's3cmd mb s3://BUCKET'
    options: []
  - name: rb
    description: Remove bucket
    usage: 's3cmd rb s3://BUCKET'
    options: []
  - name: ls
    description: List objects or buckets
    usage: 's3cmd ls [s3://BUCKET[/PREFIX]]'
    options: []
  - name: la
    description: List all object in all buckets
    usage: 's3cmd la'
    options: []
  - name: put
    description: Put file into bucket
    usage: 's3cmd put FILE [FILE...] s3://BUCKET[/PREFIX]'
    options: []
  - name: get
    description: Get file from bucket
    usage: 's3cmd get s3://BUCKET/OBJECT LOCAL_FILE'
    options: []
  - name: del
    description: Delete file from bucket
    usage: 's3cmd del s3://BUCKET/OBJECT'
    options: []
  - name: rm
    description: Delete file from bucket (alias for del)
    usage: 's3cmd rm s3://BUCKET/OBJECT'
    options: []
  - name: restore
    description: Restore file from Glacier storage
    usage: 's3cmd restore s3://BUCKET/OBJECT'
    options: []
  - name: sync
    description: Synchronize a directory tree to S3 (checks files freshness using size and md5 checksum, unless overridden by options, see below)
    usage: 's3cmd sync LOCAL_DIR s3://BUCKET[/PREFIX] or s3://BUCKET[/PREFIX] LOCAL_DIR'
    options: []
  - name: du
    description: Disk usage by buckets
    usage: 's3cmd du [s3://BUCKET[/PREFIX]]'
    options: []
  - name: info
    description: Get various information about Buckets or Files
    usage: 's3cmd info s3://BUCKET[/OBJECT]'
    options: []
  - name: cp
    description: Copy object
    usage: 's3cmd cp s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]'
    options: []
  - name: modify
    description: Modify object metadata
    usage: 's3cmd modify s3://BUCKET1/OBJECT'
    options: []
  - name: mv
    description: Move object
    usage: 's3cmd mv s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]'
    options: []
  - name: setacl
    description: Modify Access control list for Bucket or Files
    usage: 's3cmd setacl s3://BUCKET[/OBJECT]'
    options: []
  - name: setpolicy
    description: Modify Bucket Policy
    usage: 's3cmd setpolicy FILE s3://BUCKET'
    options: []
  - name: delpolicy
    description: Delete Bucket Policy
    usage: 's3cmd delpolicy s3://BUCKET'
    options: []
  - name: setcors
    description: Modify Bucket CORS
    usage: 's3cmd setcors FILE s3://BUCKET'
    options: []
  - name: delcors
    description: Delete Bucket CORS
    usage: 's3cmd delcors s3://BUCKET'
    options: []
  - name: payer
    description: Modify Bucket Requester Pays policy
    usage: 's3cmd payer s3://BUCKET'
    options: []
  - name: multipart
    description: Show multipart uploads
    usage: 's3cmd multipart s3://BUCKET [Id]'
    options: []
  - name: abortmp
    description: Abort a multipart upload
    usage: 's3cmd abortmp s3://BUCKET/OBJECT Id'
    options: []
  - name: listmp
    description: List parts of a multipart upload
    usage: 's3cmd listmp s3://BUCKET/OBJECT Id'
    options: []
  - name: accesslog
    description: Enable/disable bucket access logging
    usage: 's3cmd accesslog s3://BUCKET'
    options: []
  - name: sign
    description: Sign arbitrary string using the secret key
    usage: 's3cmd sign STRING-TO-SIGN'
    options: []
  - name: signurl
    description: Sign an S3 URL to provide limited public access with expiry
    usage: 's3cmd signurl s3://BUCKET/OBJECT <expiry_epoch|+expiry_offset>'
    options: []
  - name: fixbucket
    description: Fix invalid file names in a bucket
    usage: 's3cmd fixbucket s3://BUCKET[/PREFIX]'
    options: []
  - name: ws-create
    description: Create Website from bucket
    usage: 's3cmd ws-create s3://BUCKET'
    options: []
  - name: ws-delete
    description: Delete Website
    usage: 's3cmd ws-delete s3://BUCKET'
    options: []
  - name: ws-info
    description: Info about Website
    usage: 's3cmd ws-info s3://BUCKET'
    options: []
  - name: expire
    description: Set or delete expiration rule for the bucket
    usage: 's3cmd expire s3://BUCKET'
    options: []
  - name: setlifecycle
    description: Upload a lifecycle policy for the bucket
    usage: 's3cmd setlifecycle FILE s3://BUCKET'
    options: []
  - name: getlifecycle
    description: Get a lifecycle policy for the bucket
    usage: 's3cmd getlifecycle s3://BUCKET'
    options: []
  - name: dellifecycle
    description: Remove a lifecycle policy for the bucket
    usage: 's3cmd dellifecycle s3://BUCKET'
    options: []
  - name: cflist
    description: List CloudFront distribution points
    usage: 's3cmd cflist'
    options: []
  - name: cfinfo
    description: Display CloudFront distribution point parameters
    usage: 's3cmd cfinfo [cf://DIST_ID]'
    options: []
  - name: cfcreate
    description: Create CloudFront distribution point
    usage: 's3cmd cfcreate s3://BUCKET'
    options: []
  - name: cfdelete
    description: Delete CloudFront distribution point
    usage: 's3cmd cfdelete cf://DIST_ID'
    options: []
  - name: cfmodify
    description: Change CloudFront distribution point parameters
    usage: 's3cmd cfmodify cf://DIST_ID'
    options: []
  - name: cfinvalinfo
    description: Display CloudFront invalidation request(s) status
    usage: 's3cmd cfinvalinfo cf://DIST_ID[/INVAL_ID]'
    options: []
version: s3cmd version 2.3.0
tldr: |
  > Command line tool and client for uploading, retrieving and managing data in S3 compatible object storage.
  > More information: <https://s3tools.org/s3cmd>.

  - Invoke configuration/reconfiguration tool:

  `s3cmd --configure`

  - List Buckets/Folders/Objects:

  `s3cmd ls s3://{{bucket|path/to/file}}`

  - Create Bucket/Folder:

  `s3cmd mb s3://{{bucket}}`

  - Download a specific file from a bucket:

  `s3cmd get s3://{{bucket_name}}/{{path/to/file}} {{path/to/local_file}}`

  - Upload a file to a bucket:

  `s3cmd put {{local_file}} s3://{{bucket}}/{{file}}`

  - Move an object to a specific bucket location:

  `s3cmd mv s3://{{src_bucket}}/{{src_object}} s3://{{dst_bucket}}/{{dst_object}}`

  - Delete a specific object:

  `s3cmd rm s3://{{bucket}}/{{object}}`
