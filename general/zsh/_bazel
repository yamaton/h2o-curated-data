#compdef _bazel bazel

# Auto-generated with h2o

    function _bazel_analyze-profile {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--dump[output full profile data dump either in human-readable '\''text'\'' format or script-friendly '\''raw'\'' format.]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_aquery {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--aspect_deps[How to resolve aspect dependencies when the output format is one of {xml, proto,record}. '\''off'\'' means no aspect dependencies are resolved, '\''conservative'\'' (the default) means all declared aspect dependencies are added regardless of whether they are given the rule class of direct dependencies, '\''precise'\'' means that only those aspects are added that are possibly active given the rule class of the direct dependencies. Note that precise mode requires loading other packages to evaluate a single target thus making it slower than the other modes. Also note that even precise mode is not completely precise: the decision whether to compute an aspect is decided in the analysis phase, which is not run during '\''bazel query'\''.]' \
            '--deduplicate_depsets[De-duplicate non-leaf children of a dep_set_of_files in the final proto/textproto/json output. This does not deduplicate depsets that don'\''t share an immediate parent. This does not affect the final effective list of input artifacts of the actions.]' \
            '--implicit_deps[If enabled, implicit dependencies will be included in the dependency graph over which the query operates. An implicit dependency is one that is not explicitly specified in the BUILD file but added by bazel. For cquery, this option controls filtering resolved toolchains.]' \
            '--include_artifacts[Includes names of the action inputs and outputs in the output (potentially large).]' \
            '--include_aspects[aquery, cquery: whether to include aspect-generated actions in the output. query: no-op (aspects are always followed).]' \
            '--include_commandline[Includes the content of the action command lines in the output (potentially large).]' \
            '--include_param_files[Include the content of the param files used in the command (potentially large). Note: Enabling this flag will automatically enable the -- include_commandline flag.]' \
            '--incompatible_proto_output_v2[No-op.]' \
            '--infer_universe_scope[If set and --universe_scope is unset, then a value of --universe_scope will be inferred as the list of unique target patterns in the query expression. Note that the --universe_scope value inferred for a query expression that uses universe-scoped functions (e.g.`allrdeps`) may not be what you want, so you should use this option only if you know what you are doing. See https://docs.bazel.build/versions/main/query.html#sky-query for details and examples. If --universe_scope is set, then this option'\''s value is ignored. Note: this option applies only to `query` (i.e. not `cquery`).]' \
            '--line_terminator_null[Whether each format is terminated with \0 instead of newline.]' \
            '--nodep_deps[If enabled, deps from "nodep" attributes will be included in the dependency graph over which the query operates. A common example of a "nodep" attribute is "visibility". Run and parse the output of `info buildlanguage` to learn about all the "nodep" attributes in the build language.]' \
            '--output[The format in which the aquery results should be printed. Allowed values for aquery are: text, textproto, proto, jsonproto.]' \
            '--relative_locations[If true, the location of BUILD files in xml and proto outputs will be relative. By default, the location output is an absolute path and will not be consistent across machines. You can set this option to true to have a consistent result across machines.]' \
            '--skyframe_state[Without performing extra analysis, dump the current Action Graph from Skyframe. Note: Specifying a target with --skyframe_state is currently not supported. This flag is only available with --output=proto or -- output=textproto.]' \
            '--tool_deps[Query: If disabled, dependencies on '\''host configuration'\'' or '\''execution'\'' targets will not be included in the dependency graph over which the query operates. A '\''host configuration'\'' dependency edge, such as the one from any '\''proto_library'\'' rule to the Protocol Compiler, usually points to a tool executed during the build rather than a part of the same '\''target'\'' program. Cquery: If disabled, filters out all configured targets which cross a host or execution transition from the top-level target that discovered this configured target. That means if the top-level target is in the target configuration, only configured targets also in the target configuration will be returned. If the top-level target is in the host configuration, only host configured targets will be returned. This option will NOT exclude resolved toolchains.]' \
            '--universe_scope[A comma-separated set of target patterns (additive and subtractive). The query may be performed in the universe defined by the transitive closure of the specified targets. This option is used for the query and cquery commands. For cquery, the input to this option is the targets all answers are built under and so this option may affect configurations and transitions. If this option is not specified, the top-level targets are assumed to be the targets parsed from the query expression. Note: For cquery, not specifying this option may cause the build to break if targets parsed from the query expression are not buildable with top-level options.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_build {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_canonicalize-flags {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--canonicalize_policy[Output the canonical policy, after expansion and filtering. To keep the output clean, the canonicalized command arguments will NOT be shown when this option is set to true. Note that the command specified by -- for_command affects the filtered policy, and if none is specified, the default command is '\''build'\''.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--show_warnings[Output parser warnings to standard error (e.g. for conflicting flag options).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--for_command[The command for which the options should be canonicalized.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--invocation_policy[Applies an invocation policy to the options to be canonicalized.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_clean {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--async[If true, output cleaning is asynchronous. When this command completes, it will be safe to execute new commands in the same client, even though the deletion may continue in the background.]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--expunge[If true, clean removes the entire working tree for this bazel instance, which includes all bazel-created temporary and build output files, and stops the bazel server if it is running.]' \
            '--expunge_async[If specified, clean asynchronously removes the entire working tree for this bazel instance, which includes all bazel-created temporary and build output files, and stops the bazel server if it is running. When this command completes, it will be safe to execute new commands in the same client, even though the deletion may continue in the background.]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--remove_all_convenience_symlinks[If true, all symlinks in the workspace with the prefix symlink_prefix will be deleted. Without this flag, only symlinks with the predefined suffixes are cleaned.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_coverage {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--print_relative_test_log_paths[If true, when printing the path to a test log, use relative path that makes use of the '\''testlogs'\'' convenience symlink. N.B. - A subsequent '\''build'\''/'\''test'\''/etc invocation with a different configuration can cause the target of this symlink to change, making the path printed previously no longer useful.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_verbose_timeout_warnings[If true, print additional warnings when the actual test execution time does not match the timeout defined by the test (whether implied or explicit).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--verbose_test_summary[If true, print additional information (timing, number of failed runs, etc) in the test summary.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_cquery {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--aspect_deps[How to resolve aspect dependencies when the output format is one of {xml, proto,record}. '\''off'\'' means no aspect dependencies are resolved, '\''conservative'\'' (the default) means all declared aspect dependencies are added regardless of whether they are given the rule class of direct dependencies, '\''precise'\'' means that only those aspects are added that are possibly active given the rule class of the direct dependencies. Note that precise mode requires loading other packages to evaluate a single target thus making it slower than the other modes. Also note that even precise mode is not completely precise: the decision whether to compute an aspect is decided in the analysis phase, which is not run during '\''bazel query'\''.]' \
            '--implicit_deps[If enabled, implicit dependencies will be included in the dependency graph over which the query operates. An implicit dependency is one that is not explicitly specified in the BUILD file but added by bazel. For cquery, this option controls filtering resolved toolchains.]' \
            '--include_aspects[aquery, cquery: whether to include aspect-generated actions in the output. query: no-op (aspects are always followed).]' \
            '--infer_universe_scope[If set and --universe_scope is unset, then a value of --universe_scope will be inferred as the list of unique target patterns in the query expression. Note that the --universe_scope value inferred for a query expression that uses universe-scoped functions (e.g.`allrdeps`) may not be what you want, so you should use this option only if you know what you are doing. See https://docs.bazel.build/versions/main/query.html#sky-query for details and examples. If --universe_scope is set, then this option'\''s value is ignored. Note: this option applies only to `query` (i.e. not `cquery`).]' \
            '--line_terminator_null[Whether each format is terminated with \0 instead of newline.]' \
            '--nodep_deps[If enabled, deps from "nodep" attributes will be included in the dependency graph over which the query operates. A common example of a "nodep" attribute is "visibility". Run and parse the output of `info buildlanguage` to learn about all the "nodep" attributes in the build language.]' \
            '--output[The format in which the cquery results should be printed. Allowed values for cquery are: label, label_kind, textproto, transitions, proto, jsonproto. If you select '\''transitions'\'', you also have to specify the -- transitions=(lite|full) option.]' \
            '--relative_locations[If true, the location of BUILD files in xml and proto outputs will be relative. By default, the location output is an absolute path and will not be consistent across machines. You can set this option to true to have a consistent result across machines.]' \
            '--show_config_fragments[Shows the configuration fragments required by a rule and its transitive dependencies. This can be useful for evaluating how much a configured target graph can be trimmed.]':file:_files \
            '--tool_deps[Query: If disabled, dependencies on '\''host configuration'\'' or '\''execution'\'' targets will not be included in the dependency graph over which the query operates. A '\''host configuration'\'' dependency edge, such as the one from any '\''proto_library'\'' rule to the Protocol Compiler, usually points to a tool executed during the build rather than a part of the same '\''target'\'' program. Cquery: If disabled, filters out all configured targets which cross a host or execution transition from the top-level target that discovered this configured target. That means if the top-level target is in the target configuration, only configured targets also in the target configuration will be returned. If the top-level target is in the host configuration, only host configured targets will be returned. This option will NOT exclude resolved toolchains.]' \
            '--transitions[The format in which cquery will print transition information.]' \
            '--universe_scope[A comma-separated set of target patterns (additive and subtractive). The query may be performed in the universe defined by the transitive closure of the specified targets. This option is used for the query and cquery commands. For cquery, the input to this option is the targets all answers are built under and so this option may affect configurations and transitions. If this option is not specified, the top-level targets are assumed to be the targets parsed from the query expression. Note: For cquery, not specifying this option may cause the build to break if targets parsed from the query expression are not buildable with top-level options.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--print_relative_test_log_paths[If true, when printing the path to a test log, use relative path that makes use of the '\''testlogs'\'' convenience symlink. N.B. - A subsequent '\''build'\''/'\''test'\''/etc invocation with a different configuration can cause the target of this symlink to change, making the path printed previously no longer useful.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_verbose_timeout_warnings[If true, print additional warnings when the actual test execution time does not match the timeout defined by the test (whether implied or explicit).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--verbose_test_summary[If true, print additional information (timing, number of failed runs, etc) in the test summary.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_dump {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--action_cache[Dump action cache content.]' \
            '--packages[Dump package cache content.]' \
            '--rule_classes[Dump rule classes.]' \
            '--rules[Dump rules, including counts and memory usage (if memory is tracked).]' \
            '--skyframe[Dump Skyframe graph: '\''off'\'', '\''summary'\'', or '\''detailed'\''.]' \
            '--skylark_memory[Dumps a pprof-compatible memory profile to the specified path. To learn more please see https://github.com/google/pprof.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_fetch {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_info {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_make_env[Include the "Make" environment in the output.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_license {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_mobile-install {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--adb[adb binary to use for the '\''mobile-install'\'' command. If unspecified, the one in the Android SDK specified by the --android_sdk command line option (or the default SDK if --android_sdk is not specified) is used.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--incremental[Whether to do an incremental install. If true, try to avoid unnecessary additional work by reading the state of the device the code is to be installed on and using that information to avoid unnecessary work. If false (the default), always do a full install.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--split_apks[Whether to use split apks to install and update the application on the device. Works only with devices with Marshmallow or later]' \
            '--adb_arg[Extra arguments to pass to adb. Usually used to designate a device to install to.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--debug_app[Whether to wait for the debugger before starting the app.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--device[The adb device serial number. If not specified, the first device will be used.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--start[How the app should be started after installing it. Set to WARM to preserve and restore application state on incremental installs.]' \
            '--start_app[Whether to start the app after installing it.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--incremental_install_verbosity[The verbosity for incremental install. Set to 1 for debug logging.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_print_action {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--print_action_mnemonics[Lists which mnemonics to filter print_action data by, no filtering takes place when left empty.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_query {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--aspect_deps[How to resolve aspect dependencies when the output format is one of {xml, proto,record}. '\''off'\'' means no aspect dependencies are resolved, '\''conservative'\'' (the default) means all declared aspect dependencies are added regardless of whether they are given the rule class of direct dependencies, '\''precise'\'' means that only those aspects are added that are possibly active given the rule class of the direct dependencies. Note that precise mode requires loading other packages to evaluate a single target thus making it slower than the other modes. Also note that even precise mode is not completely precise: the decision whether to compute an aspect is decided in the analysis phase, which is not run during '\''bazel query'\''.]' \
            '--implicit_deps[If enabled, implicit dependencies will be included in the dependency graph over which the query operates. An implicit dependency is one that is not explicitly specified in the BUILD file but added by bazel. For cquery, this option controls filtering resolved toolchains.]' \
            '--include_aspects[aquery, cquery: whether to include aspect-generated actions in the output. query: no-op (aspects are always followed).]' \
            '--incompatible_lexicographical_output[If this option is set, sorts --order_output=auto output in lexicographical order.]' \
            '--infer_universe_scope[If set and --universe_scope is unset, then a value of --universe_scope will be inferred as the list of unique target patterns in the query expression. Note that the --universe_scope value inferred for a query expression that uses universe-scoped functions (e.g.`allrdeps`) may not be what you want, so you should use this option only if you know what you are doing. See https://docs.bazel.build/versions/main/query.html#sky-query for details and examples. If --universe_scope is set, then this option'\''s value is ignored. Note: this option applies only to `query` (i.e. not `cquery`).]' \
            '--line_terminator_null[Whether each format is terminated with \0 instead of newline.]' \
            '--nodep_deps[If enabled, deps from "nodep" attributes will be included in the dependency graph over which the query operates. A common example of a "nodep" attribute is "visibility". Run and parse the output of `info buildlanguage` to learn about all the "nodep" attributes in the build language.]' \
            '--noorder_results[Output the results in dependency-ordered (default) or unordered fashion. The unordered output is faster but only supported when --output is not minrank, maxrank, or graph.]' \
            '--null[Whether each format is terminated with \0 instead of newline.]' \
            '--order_output[Output the results unordered (no), dependency-ordered (deps), or fully ordered (full). The default is '\''auto'\'', meaning that results are output either dependency-ordered or fully ordered, depending on the output formatter (dependency-ordered for proto, minrank, maxrank, and graph, fully ordered for all others). When output is fully ordered, nodes are printed in a fully deterministic (total) order. First, all nodes are sorted alphabetically. Then, each node in the list is used as the start of a postorder depth-first search in which outgoing edges to unvisited nodes are traversed in alphabetical order of the successor nodes. Finally, nodes are printed in the reverse of the order in which they were visited.]' \
            '--order_results[Output the results in dependency-ordered (default) or unordered fashion. The unordered output is faster but only supported when --output is not minrank, maxrank, or graph.]' \
            '--output[The format in which the query results should be printed. Allowed values for query are: build, graph, label, label_kind, location, maxrank, minrank, package, proto, xml.]' \
            '--query_file[If set, query will read the query from the file named here, rather than on the command line. It is an error to specify a file here as well as a command-line query.]' \
            '--relative_locations[If true, the location of BUILD files in xml and proto outputs will be relative. By default, the location output is an absolute path and will not be consistent across machines. You can set this option to true to have a consistent result across machines.]' \
            '--strict_test_suite[If true, the tests() expression gives an error if it encounters a test_suite containing non-test targets.]' \
            '--tool_deps[Query: If disabled, dependencies on '\''host configuration'\'' or '\''execution'\'' targets will not be included in the dependency graph over which the query operates. A '\''host configuration'\'' dependency edge, such as the one from any '\''proto_library'\'' rule to the Protocol Compiler, usually points to a tool executed during the build rather than a part of the same '\''target'\'' program. Cquery: If disabled, filters out all configured targets which cross a host or execution transition from the top-level target that discovered this configured target. That means if the top-level target is in the target configuration, only configured targets also in the target configuration will be returned. If the top-level target is in the host configuration, only host configured targets will be returned. This option will NOT exclude resolved toolchains.]' \
            '--universe_scope[A comma-separated set of target patterns (additive and subtractive). The query may be performed in the universe defined by the transitive closure of the specified targets. This option is used for the query and cquery commands. For cquery, the input to this option is the targets all answers are built under and so this option may affect configurations and transitions. If this option is not specified, the top-level targets are assumed to be the targets parsed from the query expression. Note: For cquery, not specifying this option may cause the build to break if targets parsed from the query expression are not buildable with top-level options.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_run {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--script_path[If set, write a shell script to the given file which invokes the target. If this option is set, the target is not run from bazel. Use '\''bazel run --script_path=foo //foo && ./foo'\'' to invoke target '\''//foo'\'' This differs from '\''bazel run //foo'\'' in that the bazel lock is released and the executable is connected to the terminal'\''s stdin.]':file:_files \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_shutdown {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_sync {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--configure[Only sync repositories marked as '\''configure'\'' for system-configuration purpose.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--only[If this option is given, only sync the repositories specified with this option. Still consider all (or all configure-like, of --configure is given) outdated.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_test {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--print_relative_test_log_paths[If true, when printing the path to a test log, use relative path that makes use of the '\''testlogs'\'' convenience symlink. N.B. - A subsequent '\''build'\''/'\''test'\''/etc invocation with a different configuration can cause the target of this symlink to change, making the path printed previously no longer useful.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_verbose_timeout_warnings[If true, print additional warnings when the actual test execution time does not match the timeout defined by the test (whether implied or explicit).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--verbose_test_summary[If true, print additional information (timing, number of failed runs, etc) in the test summary.]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_version {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--gnu_format[If set, write the version to stdout using the conventions described in the GNU standards.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }


function _bazel {
    local line state

    function _commands {
        local -a commands
        commands=(
            'analyze-profile:Analyzes build profile data.'
            'aquery:Analyzes the given targets and queries the action graph.'
            'build:Builds the specified targets.'
            'canonicalize-flags:Canonicalizes a list of bazel options.'
            'clean:Removes output files and optionally stops the server.'
            'coverage:Generates code coverage report for specified test targets.'
            'cquery:Loads, analyzes, and queries the specified targets w/ configurations.'
            'dump:Dumps the internal state of the bazel server process.'
            'fetch:Fetches external repositories that are prerequisites to the targets.'
            'info:Displays runtime info about the bazel server.'
            'license:Prints the license of this software.'
            'mobile-install:Installs targets to mobile devices.'
            'print_action:Prints the command line args for compiling a file.'
            'query:Executes a dependency graph query.'
            'run:Runs the specified target.'
            'shutdown:Stops the bazel server.'
            'sync:Syncs all repositories specified in the workspace file'
            'test:Builds and runs the specified test targets.'
            'version:Prints version information for bazel.'
        )
        _describe 'command' commands
    }
 

    _arguments -C \
        ': :->cmd' \
        '*:: :->subcmd'

    case $state in
    (cmd)
        _commands
        ;;
    (subcmd)
        case $line[1] in
        (analyze-profile)
            _bazel_analyze-profile
            ;;

        (aquery)
            _bazel_aquery
            ;;

        (build)
            _bazel_build
            ;;

        (canonicalize-flags)
            _bazel_canonicalize-flags
            ;;

        (clean)
            _bazel_clean
            ;;

        (coverage)
            _bazel_coverage
            ;;

        (cquery)
            _bazel_cquery
            ;;

        (dump)
            _bazel_dump
            ;;

        (fetch)
            _bazel_fetch
            ;;

        (info)
            _bazel_info
            ;;

        (license)
            _bazel_license
            ;;

        (mobile-install)
            _bazel_mobile-install
            ;;

        (print_action)
            _bazel_print_action
            ;;

        (query)
            _bazel_query
            ;;

        (run)
            _bazel_run
            ;;

        (shutdown)
            _bazel_shutdown
            ;;

        (sync)
            _bazel_sync
            ;;

        (test)
            _bazel_test
            ;;

        (version)
            _bazel_version
            ;;

        esac
        ;;
     esac

}

