#compdef _bazel bazel

# Auto-generated with h2o

    function _bazel_analyze-profile {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--dump[output full profile data dump either in human-readable '\''text'\'' format or script-friendly '\''raw'\'' format.]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_aquery {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--aspect_deps[How to resolve aspect dependencies when the output format is one of {xml, proto,record}. '\''off'\'' means no aspect dependencies are resolved, '\''conservative'\'' (the default) means all declared aspect dependencies are added regardless of whether they are given the rule class of direct dependencies, '\''precise'\'' means that only those aspects are added that are possibly active given the rule class of the direct dependencies. Note that precise mode requires loading other packages to evaluate a single target thus making it slower than the other modes. Also note that even precise mode is not completely precise: the decision whether to compute an aspect is decided in the analysis phase, which is not run during '\''bazel query'\''.]' \
            '--deduplicate_depsets[De-duplicate non-leaf children of a dep_set_of_files in the final proto/textproto/json output. This does not deduplicate depsets that don'\''t share an immediate parent. This does not affect the final effective list of input artifacts of the actions.]' \
            '--implicit_deps[If enabled, implicit dependencies will be included in the dependency graph over which the query operates. An implicit dependency is one that is not explicitly specified in the BUILD file but added by bazel. For cquery, this option controls filtering resolved toolchains.]' \
            '--include_artifacts[Includes names of the action inputs and outputs in the output (potentially large).]' \
            '--include_aspects[aquery, cquery: whether to include aspect-generated actions in the output. query: no-op (aspects are always followed).]' \
            '--include_commandline[Includes the content of the action command lines in the output (potentially large).]' \
            '--include_param_files[Include the content of the param files used in the command (potentially large). Note: Enabling this flag will automatically enable the -- include_commandline flag.]' \
            '--incompatible_display_source_file_location[False by default, displays the target of the source file. If true, displays the location of line 1 of source files in location outputs. This flag only exists for migration purposes.]' \
            '--incompatible_proto_output_v2[No-op.]' \
            '--infer_universe_scope[If set and --universe_scope is unset, then a value of --universe_scope will be inferred as the list of unique target patterns in the query expression. Note that the --universe_scope value inferred for a query expression that uses universe-scoped functions (e.g.`allrdeps`) may not be what you want, so you should use this option only if you know what you are doing. See https://docs.bazel.build/versions/main/query.html#sky-query for details and examples. If --universe_scope is set, then this option'\''s value is ignored. Note: this option applies only to `query` (i.e. not `cquery`).]' \
            '--line_terminator_null[Whether each format is terminated with \0 instead of newline.]' \
            '--nodep_deps[If enabled, deps from "nodep" attributes will be included in the dependency graph over which the query operates. A common example of a "nodep" attribute is "visibility". Run and parse the output of `info buildlanguage` to learn about all the "nodep" attributes in the build language.]' \
            '--output[The format in which the aquery results should be printed. Allowed values for aquery are: text, textproto, proto, jsonproto.]' \
            '--relative_locations[If true, the location of BUILD files in xml and proto outputs will be relative. By default, the location output is an absolute path and will not be consistent across machines. You can set this option to true to have a consistent result across machines.]' \
            '--skyframe_state[Without performing extra analysis, dump the current Action Graph from Skyframe. Note: Specifying a target with --skyframe_state is currently not supported. This flag is only available with --output=proto or -- output=textproto.]' \
            '--tool_deps[Query: If disabled, dependencies on '\''host configuration'\'' or '\''execution'\'' targets will not be included in the dependency graph over which the query operates. A '\''host configuration'\'' dependency edge, such as the one from any '\''proto_library'\'' rule to the Protocol Compiler, usually points to a tool executed during the build rather than a part of the same '\''target'\'' program. Cquery: If disabled, filters out all configured targets which cross a host or execution transition from the top-level target that discovered this configured target. That means if the top-level target is in the target configuration, only configured targets also in the target configuration will be returned. If the top-level target is in the host configuration, only host configured targets will be returned. This option will NOT exclude resolved toolchains.]' \
            '--universe_scope[A comma-separated set of target patterns (additive and subtractive). The query may be performed in the universe defined by the transitive closure of the specified targets. This option is used for the query and cquery commands. For cquery, the input to this option is the targets all answers are built under and so this option may affect configurations and transitions. If this option is not specified, the top-level targets are assumed to be the targets parsed from the query expression. Note: For cquery, not specifying this option may cause the build to break if targets parsed from the query expression are not buildable with top-level options.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_build {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_canonicalize-flags {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--canonicalize_policy[Output the canonical policy, after expansion and filtering. To keep the output clean, the canonicalized command arguments will NOT be shown when this option is set to true. Note that the command specified by -- for_command affects the filtered policy, and if none is specified, the default command is '\''build'\''.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--show_warnings[Output parser warnings to standard error (e.g. for conflicting flag options).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--for_command[The command for which the options should be canonicalized.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--invocation_policy[Applies an invocation policy to the options to be canonicalized.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_clean {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--async[If true, output cleaning is asynchronous. When this command completes, it will be safe to execute new commands in the same client, even though the deletion may continue in the background.]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--expunge[If true, clean removes the entire working tree for this bazel instance, which includes all bazel-created temporary and build output files, and stops the bazel server if it is running.]' \
            '--expunge_async[If specified, clean asynchronously removes the entire working tree for this bazel instance, which includes all bazel-created temporary and build output files, and stops the bazel server if it is running. When this command completes, it will be safe to execute new commands in the same client, even though the deletion may continue in the background.]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--remove_all_convenience_symlinks[If true, all symlinks in the workspace with the prefix symlink_prefix will be deleted. Without this flag, only symlinks with the predefined suffixes are cleaned.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_coverage {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--print_relative_test_log_paths[If true, when printing the path to a test log, use relative path that makes use of the '\''testlogs'\'' convenience symlink. N.B. - A subsequent '\''build'\''/'\''test'\''/etc invocation with a different configuration can cause the target of this symlink to change, making the path printed previously no longer useful.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--test_verbose_timeout_warnings[If true, print additional warnings when the actual test execution time does not match the timeout defined by the test (whether implied or explicit).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--verbose_test_summary[If true, print additional information (timing, number of failed runs, etc) in the test summary.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_cquery {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--aspect_deps[How to resolve aspect dependencies when the output format is one of {xml, proto,record}. '\''off'\'' means no aspect dependencies are resolved, '\''conservative'\'' (the default) means all declared aspect dependencies are added regardless of whether they are given the rule class of direct dependencies, '\''precise'\'' means that only those aspects are added that are possibly active given the rule class of the direct dependencies. Note that precise mode requires loading other packages to evaluate a single target thus making it slower than the other modes. Also note that even precise mode is not completely precise: the decision whether to compute an aspect is decided in the analysis phase, which is not run during '\''bazel query'\''.]' \
            '--implicit_deps[If enabled, implicit dependencies will be included in the dependency graph over which the query operates. An implicit dependency is one that is not explicitly specified in the BUILD file but added by bazel. For cquery, this option controls filtering resolved toolchains.]' \
            '--include_aspects[aquery, cquery: whether to include aspect-generated actions in the output. query: no-op (aspects are always followed).]' \
            '--incompatible_display_source_file_location[False by default, displays the target of the source file. If true, displays the location of line 1 of source files in location outputs. This flag only exists for migration purposes.]' \
            '--infer_universe_scope[If set and --universe_scope is unset, then a value of --universe_scope will be inferred as the list of unique target patterns in the query expression. Note that the --universe_scope value inferred for a query expression that uses universe-scoped functions (e.g.`allrdeps`) may not be what you want, so you should use this option only if you know what you are doing. See https://docs.bazel.build/versions/main/query.html#sky-query for details and examples. If --universe_scope is set, then this option'\''s value is ignored. Note: this option applies only to `query` (i.e. not `cquery`).]' \
            '--line_terminator_null[Whether each format is terminated with \0 instead of newline.]' \
            '--nodep_deps[If enabled, deps from "nodep" attributes will be included in the dependency graph over which the query operates. A common example of a "nodep" attribute is "visibility". Run and parse the output of `info buildlanguage` to learn about all the "nodep" attributes in the build language.]' \
            '--output[The format in which the cquery results should be printed. Allowed values for cquery are: label, label_kind, textproto, transitions, proto, jsonproto. If you select '\''transitions'\'', you also have to specify the -- transitions=(lite|full) option.]' \
            '--relative_locations[If true, the location of BUILD files in xml and proto outputs will be relative. By default, the location output is an absolute path and will not be consistent across machines. You can set this option to true to have a consistent result across machines.]' \
            '--show_config_fragments[Shows the configuration fragments required by a rule and its transitive dependencies. This can be useful for evaluating how much a configured target graph can be trimmed.]':file:_files \
            '--tool_deps[Query: If disabled, dependencies on '\''host configuration'\'' or '\''execution'\'' targets will not be included in the dependency graph over which the query operates. A '\''host configuration'\'' dependency edge, such as the one from any '\''proto_library'\'' rule to the Protocol Compiler, usually points to a tool executed during the build rather than a part of the same '\''target'\'' program. Cquery: If disabled, filters out all configured targets which cross a host or execution transition from the top-level target that discovered this configured target. That means if the top-level target is in the target configuration, only configured targets also in the target configuration will be returned. If the top-level target is in the host configuration, only host configured targets will be returned. This option will NOT exclude resolved toolchains.]' \
            '--transitions[The format in which cquery will print transition information.]' \
            '--universe_scope[A comma-separated set of target patterns (additive and subtractive). The query may be performed in the universe defined by the transitive closure of the specified targets. This option is used for the query and cquery commands. For cquery, the input to this option is the targets all answers are built under and so this option may affect configurations and transitions. If this option is not specified, the top-level targets are assumed to be the targets parsed from the query expression. Note: For cquery, not specifying this option may cause the build to break if targets parsed from the query expression are not buildable with top-level options.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--print_relative_test_log_paths[If true, when printing the path to a test log, use relative path that makes use of the '\''testlogs'\'' convenience symlink. N.B. - A subsequent '\''build'\''/'\''test'\''/etc invocation with a different configuration can cause the target of this symlink to change, making the path printed previously no longer useful.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--test_verbose_timeout_warnings[If true, print additional warnings when the actual test execution time does not match the timeout defined by the test (whether implied or explicit).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--verbose_test_summary[If true, print additional information (timing, number of failed runs, etc) in the test summary.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_dump {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--action_cache[Dump action cache content.]' \
            '--packages[Dump package cache content.]' \
            '--rule_classes[Dump rule classes.]' \
            '--rules[Dump rules, including counts and memory usage (if memory is tracked).]' \
            '--skyframe[Dump Skyframe graph: '\''off'\'', '\''summary'\'', or '\''detailed'\''.]' \
            '--skylark_memory[Dumps a pprof-compatible memory profile to the specified path. To learn more please see https://github.com/google/pprof.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_fetch {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_help {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--help_verbosity[Select the verbosity of the help command.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--long[Show full description of each option, instead of just its name.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--short[Show only the names of the options, not their types or meanings.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_info {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_make_env[Include the "Make" environment in the output.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_license {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_mobile-install {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--mode[Select how to run mobile-install. "classic" runs the current version of mobile-install. "skylark" uses the new Starlark version, which has support for android_test.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--adb[adb binary to use for the '\''mobile-install'\'' command. If unspecified, the one in the Android SDK specified by the --android_sdk command line option (or the default SDK if --android_sdk is not specified) is used.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--incremental[Whether to do an incremental install. If true, try to avoid unnecessary additional work by reading the state of the device the code is to be installed on and using that information to avoid unnecessary work. If false (the default), always do a full install.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--split_apks[Whether to use split apks to install and update the application on the device. Works only with devices with Marshmallow or later]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--adb_arg[Extra arguments to pass to adb. Usually used to designate a device to install to.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--debug_app[Whether to wait for the debugger before starting the app.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--device[The adb device serial number. If not specified, the first device will be used.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--start[How the app should be started after installing it. Set to WARM to preserve and restore application state on incremental installs.]' \
            '--start_app[Whether to start the app after installing it.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--incremental_install_verbosity[The verbosity for incremental install. Set to 1 for debug logging.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_print_action {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--print_action_mnemonics[Lists which mnemonics to filter print_action data by, no filtering takes place when left empty.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_query {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--aspect_deps[How to resolve aspect dependencies when the output format is one of {xml, proto,record}. '\''off'\'' means no aspect dependencies are resolved, '\''conservative'\'' (the default) means all declared aspect dependencies are added regardless of whether they are given the rule class of direct dependencies, '\''precise'\'' means that only those aspects are added that are possibly active given the rule class of the direct dependencies. Note that precise mode requires loading other packages to evaluate a single target thus making it slower than the other modes. Also note that even precise mode is not completely precise: the decision whether to compute an aspect is decided in the analysis phase, which is not run during '\''bazel query'\''.]' \
            '--experimental_graphless_query[If true, uses a Query implementation that does not make a copy of the graph. The new implementation only supports --order_output=no, as well as only a subset of output formatters.]' \
            '--implicit_deps[If enabled, implicit dependencies will be included in the dependency graph over which the query operates. An implicit dependency is one that is not explicitly specified in the BUILD file but added by bazel. For cquery, this option controls filtering resolved toolchains.]' \
            '--include_aspects[aquery, cquery: whether to include aspect-generated actions in the output. query: no-op (aspects are always followed).]' \
            '--incompatible_display_source_file_location[False by default, displays the target of the source file. If true, displays the location of line 1 of source files in location outputs. This flag only exists for migration purposes.]' \
            '--incompatible_lexicographical_output[If this option is set, sorts --order_output=auto output in lexicographical order.]' \
            '--infer_universe_scope[If set and --universe_scope is unset, then a value of --universe_scope will be inferred as the list of unique target patterns in the query expression. Note that the --universe_scope value inferred for a query expression that uses universe-scoped functions (e.g.`allrdeps`) may not be what you want, so you should use this option only if you know what you are doing. See https://docs.bazel.build/versions/main/query.html#sky-query for details and examples. If --universe_scope is set, then this option'\''s value is ignored. Note: this option applies only to `query` (i.e. not `cquery`).]' \
            '--line_terminator_null[Whether each format is terminated with \0 instead of newline.]' \
            '--nodep_deps[If enabled, deps from "nodep" attributes will be included in the dependency graph over which the query operates. A common example of a "nodep" attribute is "visibility". Run and parse the output of `info buildlanguage` to learn about all the "nodep" attributes in the build language.]' \
            '--noorder_results[Output the results in dependency-ordered (default) or unordered fashion. The unordered output is faster but only supported when --output is not minrank, maxrank, or graph.]' \
            '--null[Whether each format is terminated with \0 instead of newline.]' \
            '--order_output[Output the results unordered (no), dependency-ordered (deps), or fully ordered (full). The default is '\''auto'\'', meaning that results are output either dependency-ordered or fully ordered, depending on the output formatter (dependency-ordered for proto, minrank, maxrank, and graph, fully ordered for all others). When output is fully ordered, nodes are printed in a fully deterministic (total) order. First, all nodes are sorted alphabetically. Then, each node in the list is used as the start of a postorder depth-first search in which outgoing edges to unvisited nodes are traversed in alphabetical order of the successor nodes. Finally, nodes are printed in the reverse of the order in which they were visited.]' \
            '--order_results[Output the results in dependency-ordered (default) or unordered fashion. The unordered output is faster but only supported when --output is not minrank, maxrank, or graph.]' \
            '--output[The format in which the query results should be printed. Allowed values for query are: build, graph, label, label_kind, location, maxrank, minrank, package, proto, xml.]' \
            '--query_file[If set, query will read the query from the file named here, rather than on the command line. It is an error to specify a file here as well as a command-line query.]' \
            '--relative_locations[If true, the location of BUILD files in xml and proto outputs will be relative. By default, the location output is an absolute path and will not be consistent across machines. You can set this option to true to have a consistent result across machines.]' \
            '--strict_test_suite[If true, the tests() expression gives an error if it encounters a test_suite containing non-test targets.]' \
            '--tool_deps[Query: If disabled, dependencies on '\''host configuration'\'' or '\''execution'\'' targets will not be included in the dependency graph over which the query operates. A '\''host configuration'\'' dependency edge, such as the one from any '\''proto_library'\'' rule to the Protocol Compiler, usually points to a tool executed during the build rather than a part of the same '\''target'\'' program. Cquery: If disabled, filters out all configured targets which cross a host or execution transition from the top-level target that discovered this configured target. That means if the top-level target is in the target configuration, only configured targets also in the target configuration will be returned. If the top-level target is in the host configuration, only host configured targets will be returned. This option will NOT exclude resolved toolchains.]' \
            '--universe_scope[A comma-separated set of target patterns (additive and subtractive). The query may be performed in the universe defined by the transitive closure of the specified targets. This option is used for the query and cquery commands. For cquery, the input to this option is the targets all answers are built under and so this option may affect configurations and transitions. If this option is not specified, the top-level targets are assumed to be the targets parsed from the query expression. Note: For cquery, not specifying this option may cause the build to break if targets parsed from the query expression are not buildable with top-level options.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_run {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--script_path[If set, write a shell script to the given file which invokes the target. If this option is set, the target is not run from bazel. Use '\''bazel run --script_path=foo //foo && ./foo'\'' to invoke target '\''//foo'\'' This differs from '\''bazel run //foo'\'' in that the bazel lock is released and the executable is connected to the terminal'\''s stdin.]':file:_files \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_shutdown {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--iff_heap_size_greater_than[Iff non-zero, then shutdown will only shut down the server if the total memory (in MB) consumed by the JVM exceeds this value.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_sync {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--configure[Only sync repositories marked as '\''configure'\'' for system-configuration purpose.]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--only[If this option is given, only sync the repositories specified with this option. Still consider all (or all configure-like, of --configure is given) outdated.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }

    function _bazel_test {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--check_up_to_date[Don'\''t perform the build, just check if it is up-to-date. If all targets are up-to-date, the build completes successfully. If any step needs to be executed an error is reported and the build fails.]' \
            '--experimental_delay_virtual_input_materialization[If set to true, creates virtual inputs (like params files) only inside the sandbox, not in the execroot, which fixes a race condition when using the dynamic scheduler. This flag exists purely to support rolling this bug fix out.]' \
            '--experimental_docker_image[Specify a Docker image name (e.g. "ubuntu:latest") that should be used to execute a sandboxed action when using the docker strategy and the action itself doesn'\''t already have a container-image attribute in its remote_execution_properties in the platform description. The value of this flag is passed verbatim to '\''docker run'\'', so it supports the same syntax and mechanisms as Docker itself.]' \
            '--experimental_docker_privileged[If enabled, Bazel will pass the --privileged flag to '\''docker run'\'' when running actions. This might be required by your build, but it might also result in reduced hermeticity.]' \
            '--experimental_docker_use_customized_images[If enabled, injects the uid and gid of the current user into the Docker image before using it. This is required if your build / tests depend on the user having a name and home directory inside the container. This is on by default, but you can disable it in case the automatic image customization feature doesn'\''t work in your case or you know that you don'\''t need it.]' \
            '--experimental_docker_verbose[If enabled, Bazel will print more verbose messages about the Docker sandbox strategy.]' \
            '--experimental_enable_docker_sandbox[Enable Docker-based sandboxing. This option has no effect if Docker is not installed.]' \
            '--experimental_inprocess_symlink_creation[Whether to make direct file system calls to create symlink trees]' \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_remotable_source_manifests[Whether to make source manifest actions remotable]' \
            '--experimental_reuse_sandbox_directories[If set to true, directories used by sandboxed non-worker execution may be reused to avoid unnecessary setup costs.]' \
            '--experimental_sandbox_async_tree_delete_idle_threads[If 0, delete sandbox trees as soon as an action completes (causing completion of the action to be delayed). If greater than zero, execute the deletion of such threes on an asynchronous thread pool that has size 1 when the build is running and grows to the size specified by this flag when the server is idle.]' \
            '--experimental_sandboxfs_map_symlink_targets[If true, maps the targets of symbolic links specified as action inputs into the sandbox. This feature exists purely to workaround buggy rules that do not do this on their own and should be removed once all such rules are fixed.]' \
            '--experimental_sandboxfs_path[Path to the sandboxfs binary to use when --experimental_use_sandboxfs is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--experimental_split_coverage_postprocessing[If true, then Bazel will run coverage postprocessing for test in a new spawn.]' \
            '--experimental_split_xml_generation[If this flag is set, and a test action does not generate a test.xml file, then Bazel uses a separate action to generate a dummy test.xml file containing the test log. Otherwise, Bazel generates a test.xml as part of the test action.]' \
            '--experimental_strict_fileset_output[If this option is enabled, filesets will treat all output artifacts as regular files. They will not traverse directories or be sensitive to symlinks.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--experimental_use_hermetic_linux_sandbox[If set to true, do not mount root, only mount whats provided with sandbox_add_mount_pair. Input files will be hardlinked to the sandbox instead of symlinked to from the sandbox. If action input files are located on a filesystem different from the sandbox, then the input files will be copied instead.]' \
            '--experimental_use_sandboxfs[Use sandboxfs to create the actions'\'' execroot directories instead of building a symlink tree. If "yes", the binary provided by -- experimental_sandboxfs_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_use_windows_sandbox[Use Windows sandbox to run actions. If "yes", the binary provided by -- experimental_windows_sandbox_path must be valid and correspond to a supported version of sandboxfs. If "auto", the binary may be missing or not compatible.]' \
            '--experimental_windows_sandbox_path[Path to the Windows sandbox binary to use when -- experimental_use_windows_sandbox is true. If a bare name, use the first binary of that name found in the PATH.]' \
            '--genrule_strategy[Specify how to execute genrules. This flag will be phased out. Instead, use --spawn_strategy=<value> to control all actions or -- strategy=Genrule=<value> to control genrules only.]' \
            '--incompatible_legacy_local_fallback[If set to true, enables the legacy implicit fallback from sandboxed to local strategy. This flag will eventually default to false and then become a no-op. Use --strategy, --spawn_strategy, or --dynamic_local_strategy to configure fallbacks instead.]' \
            '--incompatible_remote_symlinks[If set to true, Bazel will represent symlinks in action outputs in the remote caching/execution protocol as such. The current behavior is for remote caches/executors to follow symlinks and represent them as files. See #6631 for details.]' \
            '--jobs[The number of concurrent jobs to run. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[|*\]<float>) eg. "auto", "HOST_CPUS*.5". Values must be between 1 and 5000. Values above 2500 may cause memory issues. "auto" calculates a reasonable default based on host resources.]' \
            '--keep_going[Continue as much as possible after an error. While the target that failed and those that depend on it cannot be analyzed, other prerequisites of these targets can be.]' \
            '--loading_phase_threads[Number of parallel threads to use for the loading/analysis phase.Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". "auto" sets a reasonable default based on host resources. Must be at least 1.]' \
            '--modify_execution_info[Add or remove keys from an action'\''s execution info based on action mnemonic. Applies only to actions which support execution info. Many common actions support execution info, e.g. Genrule, CppCompile, Javac, StarlarkAction, TestRunner. When specifying multiple values, order matters because many regexes may apply to the same mnemonic.]' \
            '--persistent_android_resource_processor[Enable the persistent Android resource processor by using workers.]' \
            '--remote_allow_symlink_upload[If true, upload action symlink outputs to the remote cache. If this option is not enabled, cachable actions that output symlinks will fail.]' \
            '--spawn_strategy[Specify how spawn actions are executed by default. Accepts a commaseparated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". See https: //blog.bazel.build/2019/06/19/list-strategy.html for details.]' \
            '--strategy[Specify how to distribute compilation of other spawn actions. Accepts a comma-separated list of strategies from highest to lowest priority. For each action Bazel picks the strategy with the highest priority that can execute the action. The default value is "remote,worker,sandboxed,local". This flag overrides the values set by --spawn_strategy (and -- genrule_strategy if used with mnemonic Genrule). See https://blog.bazel. build/2019/06/19/list-strategy.html for details.]' \
            '--strategy_regexp[Override which spawn strategy should be used to execute spawn actions that have descriptions matching a certain regex_filter. See --per_file_copt for details onregex_filter matching. The first regex_filter that matches the description is used. This option overrides other flags for specifying strategy. Example: --strategy_regexp=//foo.*\.cc,-//foo/bar=local means to run actions using local strategy if their descriptions match //foo.*.cc but not //foo/bar. Example: --strategy_regexp='\''Compiling.*/bar=local -- strategy_regexp=Compiling=sandboxed will run '\''Compiling //foo/bar/baz'\'' with the '\''local'\'' strategy, but reversing the order would run it with '\''sandboxed'\''.]' \
            '--android_compiler[The Android target compiler.]' \
            '--android_crosstool_top[The location of the C++ compiler used for Android builds.]' \
            '--android_grte_top[The Android target grte_top.]' \
            '--android_manifest_merger[Selects the manifest merger to use for android_binary rules. Flag to help thetransition to the Android manifest merger from the legacy merger.]' \
            '--android_platforms[Sets the platforms that android_binary targets use. If multiple platforms are specified, then the binary is a fat APKs, which contains native binaries for each specified target platform.]' \
            '--android_sdk[Specifies Android SDK/platform that is used to build Android applications.]' \
            '--apple_compiler[The Apple target compiler. Useful for selecting variants of a toolchain (e. g. xcode-beta).]' \
            '--apple_crosstool_top[The label of the crosstool package to be used in Apple and Objc rules and their dependencies.]' \
            '--apple_grte_top[The Apple target grte_top.]' \
            '--cc_output_directory_tag[Specifies a suffix to be added to the configuration directory.]' \
            '--compiler[The C++ compiler to use for compiling the target.]' \
            '--coverage_output_generator[Location of the binary that is used to postprocess raw coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:lcov_merger'\''.]' \
            '--coverage_report_generator[Location of the binary that is used to generate coverage reports. This must currently be a filegroup that contains a single file, the binary. Defaults to '\''//tools/test:coverage_report_generator'\''.]' \
            '--coverage_support[Location of support files that are required on the inputs of every test action that collects code coverage. Defaults to '\''//tools/test: coverage_support'\''.]' \
            '--crosstool_top[The label of the crosstool package to be used for compiling C++ code.]' \
            '--custom_malloc[Specifies a custom malloc implementation. This setting overrides malloc attributes in build rules.]' \
            '--experimental_add_exec_constraints_to_targets[List of comma-separated regular expressions, each optionally prefixed by - (negative expression), assigned (=) to a list of comma-separated constraint value targets. If a target matches no negative expression and at least one positive expression its toolchain resolution will be performed as if it had declared the constraint values as execution constraints. Example: //demo,test=@platforms//cpus:x86_64 will add '\''x86_64'\'' to any target under //demo except for those whose name contains '\''test'\''.]' \
            '--experimental_enable_objc_cc_deps[Allows objc_* rules to depend on cc_library and causes any objc dependencies to be built with --cpu set to "ios_<--ios_cpu>" for any values in --ios_multi_cpu.]' \
            '--experimental_include_xcode_execution_requirements[If set, add a "requires-xcode:{version}" execution requirement to every Xcode action. If the xcode version has a hyphenated label, also add a "requires-xcode-label:{version_label}" execution requirement.]' \
            '--experimental_prefer_mutual_xcode[If true, use the most recent Xcode that is available both locally and remotely. If false, or if there are no mutual available versions, use the local Xcode version selected via xcode-select.]' \
            '--extra_execution_platforms[The platforms that are available as execution platforms to run actions. Platforms can be specified by exact target, or as a target pattern. These platforms will be considered before those declared in the WORKSPACE file by register_execution_platforms().]' \
            '--extra_toolchains[The toolchain rules to be considered during toolchain resolution. Toolchains can be specified by exact target, or as a target pattern. These toolchains will be considered before those declared in the WORKSPACE file by register_toolchains().]' \
            '--grte_top[A label to a checked-in libc library. The default value is selected by the crosstool toolchain, and you almost never need to override it.]' \
            '--host_compiler[The C++ compiler to use for host compilation. It is ignored if -- host_crosstool_top is not set.]' \
            '--host_crosstool_top[By default, the --crosstool_top and --compiler options are also used for the host configuration. If this flag is provided, Bazel uses the default libc and compiler for the given crosstool_top.]' \
            '--host_grte_top[If specified, this setting overrides the libc top-level directory (-- grte_top) for the host configuration.]' \
            '--host_platform[The label of a platform rule that describes the host system.]' \
            '--incompatible_disable_expand_if_all_available_in_flag_set[If true, Bazel will not allow specifying expand_if_all_available in flag_sets(see https://github.com/bazelbuild/bazel/issues/7008 for migration instructions).]' \
            '--incompatible_disable_runtimes_filegroups[Deprecated no-op.]' \
            '--incompatible_dont_emit_static_libgcc[Deprecated no-op.]' \
            '--incompatible_dont_enable_host_nonhost_crosstool_features[If true, Bazel will not enable '\''host'\'' and '\''nonhost'\'' features in the c++ toolchain (see https://github.com/bazelbuild/bazel/issues/7407 for more information).]' \
            '--incompatible_enable_android_toolchain_resolution[Use toolchain resolution to select the Android SDK for android rules (Starlark and native)]' \
            '--incompatible_linkopts_in_user_link_flags[Deprecated no-op.]' \
            '--incompatible_make_thinlto_command_lines_standalone[If true, Bazel will not reuse C++ link action command lines for lto indexing command lines (see https://github.com/bazelbuild/bazel/issues/6791 for more information).]' \
            '--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain[If true, Bazel will complain when cc_toolchain.cpu and cc_toolchain. compiler attributes are set (see https://github. com/bazelbuild/bazel/issues/7075 for migration instructions).]' \
            '--incompatible_remove_legacy_whole_archive[If true, Bazel will not link library dependencies as whole archive by default (see https://github.com/bazelbuild/bazel/issues/7362 for migration instructions).]' \
            '--incompatible_require_ctx_in_configure_features[If true, Bazel will require '\''ctx'\'' parameter in to cc_common. configure_features (see https://github.com/bazelbuild/bazel/issues/7793 for more information).]' \
            '--interface_shared_objects[Use interface shared objects if supported by the toolchain. All ELF toolchains currently support this setting.]' \
            '--ios_sdk_version[Specifies the version of the iOS SDK to use to build iOS applications. If unspecified, uses default iOS SDK version from '\''xcode_version'\''.]' \
            '--macos_sdk_version[Specifies the version of the macOS SDK to use to build macOS applications. If unspecified, uses default macOS SDK version from '\''xcode_version'\''.]' \
            '--minimum_os_version[The minimum OS version which your compilation targets.]' \
            '--platform_mappings[The location of a mapping file that describes which platform to use if none is set or which flags to set when a platform already exists. Must be relative to the main workspace root. Defaults to '\''platform_mappings'\'' (a file directly under the workspace root).]':file:_files \
            '--platforms[The labels of the platform rules describing the target platforms for the current command.]' \
            '--python2_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python3_path[Deprecated, no-op. Disabled by `--incompatible_use_python_toolchains`.]' \
            '--python_path[The absolute path of the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--python_top[The label of a py_runtime representing the Python interpreter invoked to run Python targets on the target platform. Deprecated; disabled by -- incompatible_use_python_toolchains.]' \
            '--target_platform_fallback[The label of a platform rule that should be used if no target platform is set and no platform mapping matches the current set of flags.]' \
            '--tvos_sdk_version[Specifies the version of the tvOS SDK to use to build tvOS applications. If unspecified, uses default tvOS SDK version from '\''xcode_version'\''.]' \
            '--watchos_sdk_version[Specifies the version of the watchOS SDK to use to build watchOS applications. If unspecified, uses default watchOS SDK version from '\''xcode_version'\''.]' \
            '--xcode_version[If specified, uses Xcode of the given version for relevant build actions. If unspecified, uses the executor default version of Xcode.]' \
            '--xcode_version_config[The label of the xcode_config rule to be used for selecting the Xcode version in the build configuration.]' \
            '--apple_enable_auto_dsym_dbg[Whether to force enable generating debug symbol(.dSYM) file(s) for dbg builds.]' \
            '--apple_generate_dsym[Whether to generate debug symbol(.dSYM) file(s).]' \
            '--build[Execute the build; this is the usual behaviour. Specifying --nobuild causes the build to stop before executing the build actions, returning zero iff the package loading and analysis phases completed successfully; this mode is useful for testing those phases.]' \
            '--build_runfile_links[If true, build runfiles symlink forests for all targets. If false, write only manifests when possible.]' \
            '--build_runfile_manifests[If true, write runfiles manifests for all targets. If false, omit them. Local tests will fail to run when false.]' \
            '--build_test_dwp[If enabled, when building C++ tests statically and with fission the .dwp file for the test binary will be automatically built as well.]' \
            '--cc_proto_library_header_suffixes[Sets the prefixes of header files that a cc_proto_library creates.]' \
            '--cc_proto_library_source_suffixes[Sets the prefixes of source files that a cc_proto_library creates.]' \
            '--experimental_proto_descriptor_sets_include_source_info[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_proto_extra_actions[Run extra actions for alternative Java api versions in a proto_library.]' \
            '--experimental_run_validations[Use --run_validations instead.]' \
            '--experimental_save_feature_state[Save the state of enabled and requested feautres as an output of compilation.]' \
            '--experimental_use_validation_aspect[Whether to run validation actions using aspect (for parallelism with tests).]' \
            '--fission[Specifies which compilation modes use fission for C++ compilations and links. May be any combination of {'\''fastbuild'\'', '\''dbg'\'', '\''opt'\''} or the special values '\''yes'\'' to enable all modes and '\''no'\'' to disable all modes.]' \
            '--legacy_external_runfiles[If true, build runfiles symlink forests for external repositories under . runfiles/wsname/external/repo (in addition to .runfiles/repo).]' \
            '--objc_generate_linkmap[Specifies whether to generate a linkmap file.]' \
            '--output_groups[A list of comma-separated output group names, each of which optionally prefixed by a + or a -. A group prefixed by + is added to the default set of output groups, while a group prefixed by - is removed from the default set. If at least one group is not prefixed, the default set of output groups is omitted. For example, --output_groups=+foo,+bar builds the union of the default set, foo, and bar, while --output_groups=foo,bar overrides the default set such that only foo and bar are built.]' \
            '--run_validations[Whether to run validation actions as part of the build.]' \
            '--save_temps[If set, temporary outputs from gcc will be saved. These include .s files (assembler code), .i files (preprocessed C) and .ii files (preprocessed C++).]' \
            '--action_env[Specifies the set of environment variables available to actions with target configuration. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--android_cpu[The Android target CPU.]' \
            '--android_databinding_use_androidx[Generate AndroidX-compatible data-binding files. This is only used with databinding v2.]' \
            '--android_databinding_use_v3_4_args[Use android databinding v2 with 3.4.0 argument]' \
            '--android_dynamic_mode[Determines whether C++ deps of Android rules will be linked dynamically when a cc_binary does not explicitly create a shared library. '\''default'\'' means bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--android_manifest_merger_order[Sets the order of manifests passed to the manifest merger for Android binaries. ALPHABETICAL means manifests are sorted by path relative to the execroot. ALPHABETICAL_BY_CONFIGURATION means manifests are sorted by paths relative to the configuration directory within the output directory. DEPENDENCY means manifests are ordered with each library'\''s manifest coming before the manifests of its dependencies.]' \
            '--android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--apple_bitcode[Specify the Apple bitcode mode for compile steps targeting device architectures. Values are of the form '\''\[platform=\]mode'\'', where the platform (which must be '\''ios'\'', '\''macos'\'', '\''tvos'\'', or '\''watchos'\'') is optional. If provided, the bitcode mode is applied for that platform specifically; if omitted, it is applied for all platforms. The mode must be '\''none'\'', '\''embedded_markers'\'', or '\''embedded'\''. This option may be provided multiple times.]' \
            '--aspects[Comma-separated list of aspects to be applied to top-level targets. In the list, if aspect <code>some_aspect</code> specifies required aspect providers via <code>required_aspect_providers</code>, <code>some_aspect</code> will run after every aspect that was mentioned before it in the aspects list whose advertised providers satisfy <code>some_aspect</code> required aspect providers. Moreover, <code>some_aspect</code> will run after all its required aspects specified by <code>requires</code> attribute. <code>some_aspect</code> will then have access to the values of those aspects'\'' providers. <bzl-file-label>% <aspect_name>, for example '\''//tools:my_def.bzl%my_aspect'\'', where '\''my_aspect'\'' is a top-level value from a file tools/my_def.bzl]' \
            '--build_python_zip[Build python executable zip; on on Windows, off on other platforms]' \
            '--catalyst_cpus[Comma-separated list of architectures for which to build Apple Catalyst binaries.]' \
            '--collect_code_coverage[If specified, Bazel will instrument code (using offline instrumentation where possible) and will collect coverage information during tests. Only targets that match --instrumentation_filter will be affected. Usually this option should not be specified directly - '\''bazel coverage'\'' command should be used instead.]' \
            '--compilation_mode[Specify the mode the binary will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--conlyopt[Additional option to pass to gcc when compiling C source files.]' \
            '--copt[Additional options to pass to gcc.]' \
            '--cpu[The target CPU.]' \
            '--cs_fdo_absolute_path[Use CSFDO profile information to optimize compilation. Specify the absolute path name of the zip file containing the profile file, a raw or an indexed LLVM profile file.]' \
            '--cs_fdo_instrument[Generate binaries with context sensitive FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--cs_fdo_profile[The cs_fdo_profile representing the context sensitive profile to be used for optimization.]' \
            '--cxxopt[Additional option to pass to gcc when compiling C++ source files.]' \
            '--define[Each --define option specifies an assignment for a build variable.]' \
            '--dynamic_mode[Determines whether C++ binaries will be linked dynamically. '\''default'\'' means Bazel will choose whether to link dynamically. '\''fully'\'' means all libraries will be linked dynamically. '\''off'\'' means that all libraries will be linked in mostly static mode.]' \
            '--enable_fdo_profile_absolute_path[If set, use of fdo_absolute_profile_path will raise an error.]' \
            '--enable_runfiles[Enable runfiles symlink tree; By default, it'\''s off on Windows, on on other platforms.]' \
            '--experimental_action_listener[Deprecated in favor of aspects. Use action_listener to attach an extra_action to existing build actions.]' \
            '--experimental_android_compress_java_resources[Compress Java resources in APKs]' \
            '--experimental_android_databinding_v2[Use android databinding v2]' \
            '--experimental_android_resource_shrinking[Enables resource shrinking for android_binary APKs that use ProGuard.]' \
            '--experimental_android_rewrite_dexes_with_rex[use rex tool to rewrite dex files]' \
            '--experimental_convenience_symlinks[This flag controls how the convenience symlinks (the symlinks that appear in the workspace after the build) will be managed. Possible values:]' \
            '--experimental_convenience_symlinks_bep_event[This flag controls whether or not we will post the build eventConvenienceSymlinksIdentified to the BuildEventProtocol. If the value is true, the BuildEventProtocol will have an entry for convenienceSymlinksIdentified, listing all of the convenience symlinks created in your workspace. If false, then the convenienceSymlinksIdentified entry in the BuildEventProtocol will be empty.]' \
            '--experimental_multi_cpu[This flag allows specifying multiple target CPUs. If this is specified, the --cpu option is ignored.]' \
            '--experimental_objc_fastbuild_options[Uses these strings as objc fastbuild compiler options.]' \
            '--experimental_omitfp[If true, use libunwind for stack unwinding, and compile with -fomit-framepointer and -fasynchronous-unwind-tables.]' \
            '--experimental_platform_in_output_dir[If true, the target platform is used in the output directory name instead of the CPU.]' \
            '--experimental_use_llvm_covmap[If specified, Bazel will generate llvm-cov coverage map information rather than gcov when collect_code_coverage is enabled.]' \
            '--fat_apk_cpu[Setting this option enables fat APKs, which contain native binaries for all specified target architectures, e.g., --fat_apk_cpu=x86,armeabi-v7a. If this flag is specified, then --android_cpu is ignored for dependencies of android_binary rules.]' \
            '--fat_apk_hwasan[Whether to create HWASAN splits.]' \
            '--fdo_instrument[Generate binaries with FDO instrumentation. With Clang/LLVM compiler, it also accepts the directory name under which the raw profile file(s) will be dumped at runtime.]' \
            '--fdo_optimize[Use FDO profile information to optimize compilation. Specify the name of the zip file containing the .gcda file tree, or an afdo file containing an auto profile. This flag also accepts files specified as labels, for example //foo/bar:file.afdo. Such labels must refer to input files; you may need to add an exports_files directive to the corresponding package to make the file visible to Bazel. It also accepts a raw or an indexed LLVM profile file. This flag will be superseded by fdo_profile rule.]' \
            '--fdo_prefetch_hints[Use cache prefetch hints.]' \
            '--fdo_profile[The fdo_profile representing the profile to be used for optimization.]' \
            '--features[The given features will be enabled or disabled by default for all packages. Specifying -<feature> will disable the feature globally. Negative features always override positive ones. This flag is used to enable rolling out default feature changes without a Bazel release.]' \
            '--force_pic[If enabled, all C++ compilations produce position-independent code ("fPIC"), links prefer PIC pre-built libraries over non-PIC libraries, and links produce position-independent executables ("-pie").]' \
            '--host_action_env[Specifies the set of environment variables available to actions with host or execution configurations. Variables can be either specified by name, in which case the value will be taken from the invocation environment, or by the name=value pair which sets the value independent of the invocation environment. This option can be used multiple times; for options given for the same variable, the latest wins, options for different variables accumulate.]' \
            '--host_compilation_mode[Specify the mode the tools used during the build will be built in. Values: '\''fastbuild'\'', '\''dbg'\'', '\''opt'\''.]' \
            '--host_conlyopt[Additional option to pass to gcc when compiling C source files for host tools.]' \
            '--host_copt[Additional options to pass to gcc for host tools.]' \
            '--host_cpu[The host CPU.]' \
            '--host_cxxopt[Additional options to pass to gcc for host tools.]' \
            '--host_force_python[Overrides the Python version for the host configuration. Can be "PY2" or "PY3".]' \
            '--host_linkopt[Additional option to pass to gcc when linking host tools.]' \
            '--host_macos_minimum_os[Minimum compatible macOS version for host targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--host_swiftcopt[Additional options to pass to swiftc for host tools.]' \
            '--incompatible_avoid_conflict_dlls[If enabled, all C++ dynamic linked libraries (DLLs) generated by cc_library on Windows will be renamed to name_{hash}.dll where hash is calculated based on the RepositoryName and the DLL'\''s package path. This option is useful when you have one package which depends on severals cc_library with the same name (e.g //foo/bar1:utils and //foo/bar2:utils).]' \
            '--incompatible_merge_genfiles_directory[If true, the genfiles directory is folded into the bin directory.]' \
            '--incompatible_use_platforms_repo_for_constraints[If true, constraint settings from @bazel_tools are removed.]' \
            '--instrument_test_targets[When coverage is enabled, specifies whether to consider instrumenting test rules. When set, test rules included by --instrumentation_filter are instrumented. Otherwise, test rules are always excluded from coverage instrumentation.]' \
            '--instrumentation_filter[When coverage is enabled, only rules with names included by the specified regex-based filter will be instrumented. Rules prefixed with '\''-'\'' are excluded instead. Note that only non-test rules are instrumented unless -- instrument_test_targets is enabled.]':file:_files \
            '--ios_cpu[Specifies to target CPU of iOS compilation.]' \
            '--ios_minimum_os[Minimum compatible iOS version for target simulators and devices. If unspecified, uses '\''ios_sdk_version'\''.]' \
            '--ios_multi_cpus[Comma-separated list of architectures to build an ios_application with. The result is a universal binary containing all specified architectures.]' \
            '--legacy_whole_archive[Deprecated, superseded by --incompatible_remove_legacy_whole_archive (see https://github.com/bazelbuild/bazel/issues/7362 for details). When on, use --whole-archive for cc_binary rules that have linkshared=1 and either linkstatic=1 or '\''-static'\'' in linkopts. This is for backwards compatibility only. A better alternative is to use alwayslink=1 where required.]' \
            '--linkopt[Additional option to pass to gcc when linking.]' \
            '--ltobackendopt[Additional option to pass to the LTO backend step (under -- features=thin_lto).]' \
            '--ltoindexopt[Additional option to pass to the LTO indexing step (under -- features=thin_lto).]' \
            '--macos_cpus[Comma-separated list of architectures for which to build Apple macOS binaries.]' \
            '--macos_minimum_os[Minimum compatible macOS version for targets. If unspecified, uses '\''macos_sdk_version'\''.]' \
            '--objc_debug_with_GLIBCXX[If set, and compilation mode is set to '\''dbg'\'', define GLIBCXX_DEBUG, GLIBCXX_DEBUG_PEDANTIC and GLIBCPP_CONCEPT_CHECKS.]' \
            '--objc_enable_binary_stripping[Whether to perform symbol and dead-code strippings on linked binaries. Binary strippings will be performed if both this flag and -- compilation_mode=opt are specified.]' \
            '--objccopt[Additional options to pass to Objective C compilation.]' \
            '--per_file_copt[Additional options to selectively pass to gcc when compiling certain files. This option can be passed multiple times. Syntax: regex_filter@option_1, option_2,...,option_n. Where regex_filter stands for a list of include and exclude regular expression patterns (Also see --instrumentation_filter). option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: -- per_file_copt=//foo/.*\.cc,-//foo/bar\.cc@-O0 adds the -O0 command line option to the gcc command line of all cc files in //foo/ except bar.cc.]':file:_files \
            '--per_file_ltobackendopt[Additional options to selectively pass to LTO backend (under -- features=thin_lto) when compiling certain backend objects. This option can be passed multiple times. Syntax: regex_filter@option_1,option_2,..., option_n. Where regex_filter stands for a list of include and exclude regular expression patterns. option_1 to option_n stand for arbitrary command line options. If an option contains a comma it has to be quoted with a backslash. Options can contain @. Only the first @ is used to split the string. Example: --per_file_ltobackendopt=//foo/.*\.o,-//foo/bar\.o@-O0 adds the -O0 command line option to the LTO backend command line of all o files in //foo/ except bar.o.]':file:_files \
            '--platform_suffix[Specifies a suffix to be added to the configuration directory.]' \
            '--propeller_optimize[The layout file for propeller code layout optimizations.]' \
            '--propeller_optimize_absolute_cc_profile[Absolute path name of cc_profile file for Propeller Optimized builds.]' \
            '--propeller_optimize_absolute_ld_profile[Absolute path name of ld_profile file for Propeller Optimized builds.]' \
            '--remote_download_minimal[Does not download any remote build outputs to the local machine. This flag is a shortcut for three flags: --experimental_inmemory_jdeps_files, -- experimental_inmemory_dotd_files and --remote_download_outputs=minimal.]' \
            '--remote_download_outputs[If set to '\''minimal'\'' doesn'\''t download any remote build outputs to the local machine, except the ones required by local actions. If set to '\''toplevel'\'' behaves like'\''minimal'\'' except that it also downloads outputs of top level targets to the local machine. Both options can significantly reduce build times if network bandwidth is a bottleneck.]' \
            '--remote_download_symlink_template[Instead of downloading remote build outputs to the local machine, create symbolic links. The target of the symbolic links can be specified in the form of a template string. This template string may contain {hash} and {size_bytes} that expand to the hash of the object and the size in bytes, respectively. These symbolic links may, for example, point to a FUSE file system that loads objects from the CAS on demand.]' \
            '--remote_download_toplevel[Only downloads remote outputs of top level targets to the local machine. This flag is a shortcut for three flags: -- experimental_inmemory_jdeps_files, --experimental_inmemory_dotd_files and -- remote_download_outputs=toplevel.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--run_under[Prefix to insert before the executables for the '\''test'\'' and '\''run'\'' commands. If the value is '\''foo -bar'\'', and the execution command line is '\''test_binary - baz'\'', then the final command line is '\''foo -bar test_binary -baz'\''.This can also be a label to an executable target. Some examples are: '\''valgrind'\'', '\''strace'\'', '\''strace -c'\'', '\''valgrind --quiet --num-callers=20'\'', '\''//package: target'\'', '\''//package:target --options'\''.]' \
            '--share_native_deps[If true, native libraries that contain identical functionality will be shared among different targets]' \
            '--stamp[Stamp binaries with the date, username, hostname, workspace information, etc.]' \
            '--strip[Specifies whether to strip binaries and shared libraries (using "-Wl,-- strip-debug"). The default value of '\''sometimes'\'' means strip iff -- compilation_mode=fastbuild.]' \
            '--stripopt[Additional options to pass to strip when generating a '\''<name>.stripped'\'' binary.]' \
            '--swiftcopt[Additional options to pass to Swift compilation.]' \
            '--symlink_prefix[The prefix that is prepended to any of the convenience symlinks that are created after a build. If omitted, the default value is the name of the build tool followed by a hyphen. If '\''/'\'' is passed, then no symlinks are created and no warning is emitted. Warning: the special functionality for '\''/'\'' will be deprecated soon; use --experimental_convenience_symlinks=ignore instead.]' \
            '--tvos_cpus[Comma-separated list of architectures for which to build Apple tvOS binaries.]' \
            '--tvos_minimum_os[Minimum compatible tvOS version for target simulators and devices. If unspecified, uses '\''tvos_sdk_version'\''.]' \
            '--watchos_cpus[Comma-separated list of architectures for which to build Apple watchOS binaries.]' \
            '--watchos_minimum_os[Minimum compatible watchOS version for target simulators and devices. If unspecified, uses '\''watchos_sdk_version'\''.]' \
            '--xbinary_fdo[Use XbinaryFDO profile information to optimize compilation. Specify the name of default cross binary profile. When the option is used together with --fdo_instrument/--fdo_optimize/--fdo_profile, those options will always prevail as if xbinary_fdo is never specified.]' \
            '--auto_cpu_environment_group[Declare the environment_group to use for automatically mapping cpu values to target_environment values.]' \
            '--check_licenses[Check that licensing constraints imposed by dependent packages do not conflict with distribution modes of the targets being built. By default, licenses are not checked.]' \
            '--check_visibility[If disabled, visibility errors are demoted to warnings.]' \
            '--desugar_for_android[Whether to desugar Java 8 bytecode before dexing.]' \
            '--enforce_constraints[Checks the environments each target is compatible with and reports errors if any target has dependencies that don'\''t support the same environments]' \
            '--experimental_allow_android_library_deps_without_srcs[Flag to help transition from allowing to disallowing srcs-less android_library rules with deps. The depot needs to be cleaned up to roll this out by default.]' \
            '--experimental_check_desugar_deps[Whether to double-check correct desugaring at Android binary level.]' \
            '--experimental_desugar_java8_libs[Whether to include supported Java 8 libraries in apps for legacy devices.]' \
            '--experimental_import_deps_checking[When enabled, check whether the dependencies of an aar_import are complete. This enforcement can break the build, or can just result in warnings.]' \
            '--experimental_java_proto_add_allowed_public_imports[If true, add --allowed_public_imports to the java compile actions.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_strict_java_deps[If true, checks that a Java target explicitly declares all directly used targets as dependencies.]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--incompatible_disable_native_android_rules[If enabled, direct usage of the native Android rules is disabled. Please use the Starlark Android rules from https://github. com/bazelbuild/rules_android]' \
            '--incompatible_disable_native_apple_binary_rule[If enabled, direct usage of the native apple_binary rule is disabled. Please use the Starlark rule from https://github.com/bazelbuild/rules_apple instead.]' \
            '--incompatible_force_strict_header_check_from_starlark[If enabled, set strict header checking in the Starlark API]' \
            '--incompatible_validate_top_level_header_inclusions[If true, Bazel will also validate top level directory header inclusions (see https://github.com/bazelbuild/bazel/issues/10047 for more information).]' \
            '--strict_filesets[If this option is enabled, filesets crossing package boundaries are reported as errors. It does not work when check_fileset_dependencies_recursively is disabled.]' \
            '--strict_proto_deps[Unless OFF, checks that a proto_library target explicitly declares all directly used targets as dependencies.]' \
            '--strict_system_includes[If true, headers found through system include paths (-isystem) are also required to be declared.]' \
            '--target_environment[Declares this build'\''s target environment. Must be a label reference to an "environment" rule. If specified, all top-level targets must be compatible with this environment.]' \
            '--apk_signing_method[Implementation to use to sign APKs]' \
            '--device_debug_entitlements[If set, and compilation mode is not '\''opt'\'', objc apps will include debug entitlements when signing.]' \
            '--ios_signing_cert_name[Certificate name to use for iOS signing. If not set will fall back to provisioning profile. May be the certificate'\''s keychain identity preference or (substring) of the certificate'\''s common name, as per codesign'\''s man page (SIGNING IDENTITIES).]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_config_setting_private_default_visibility[If incompatible_enforce_config_setting_visibility=false, this is a noop. Else, if this flag is false, any config_setting without an explicit visibility attribute is //visibility:public. If this flag is true, config_setting follows the same visibility logic as all other rules. See https://github.com/bazelbuild/bazel/issues/12933.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_legacy_py_provider[If set to true, native Python rules will neither produce nor consume the legacy "py" provider. Use PyInfo instead. Under this flag, passing the legacy provider to a Python target will be an error.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_enforce_config_setting_visibility[If true, enforce config_setting visibility restrictions. If false, every config_setting is visible to every target. See https://github. com/bazelbuild/bazel/issues/12932.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--allow_analysis_failures[If true, an analysis failure of a rule target results in the target'\''s propagation of an instance of AnalysisFailureInfo containing the error description, instead of resulting in a build failure.]' \
            '--analysis_testing_deps_limit[Sets the maximum number of transitive dependencies through a rule attribute with a for_analysis_testing configuration transition. Exceeding this limit will result in a rule error.]' \
            '--break_build_on_parallel_dex2oat_failure[If true dex2oat action failures will cause the build to break instead of executing dex2oat during test runtime.]' \
            '--check_tests_up_to_date[Don'\''t run tests, just check if they are up-to-date. If all tests results are up-to-date, the testing completes successfully. If any test needs to be built or executed, an error is reported and the testing fails. This option implies --check_up_to_date behavior.]' \
            '--experimental_android_use_parallel_dex2oat[Use dex2oat in parallel to possibly speed up android_test.]' \
            '--flaky_test_attempts[Each test will be retried up to the specified number of times in case of any test failure. Tests that required more than one attempt to pass are marked as '\''FLAKY'\'' in the test summary. Normally the value specified is just an integer or the string '\''default'\''. If an integer, then all tests will be run up to N times. If '\''default'\'', then only a single test attempt will be made for regular tests and three for tests marked explicitly as flaky by their rule (flaky=1 attribute). Alternate syntax: regex_filter@flaky_test_attempts. Where flaky_test_attempts is as above and regex_filter stands for a list of include and exclude regular expression patterns (Also see --runs_per_test). Example: --flaky_test_attempts=//foo/. *,-//foo/bar/.*@3 deflakes all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, behavior is as if '\''default'\'' above.]' \
            '--ios_memleaks[Enable checking for memory leaks in ios_test targets.]' \
            '--ios_simulator_device[The device to simulate when running an iOS application in the simulator, e. g. '\''iPhone 6'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--ios_simulator_version[The version of iOS to run on the simulator when running or testing. This is ignored for ios_test rules if a target device is specified in the rule.]' \
            '--local_test_jobs[The max number of local test jobs to run concurrently. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". 0 means local resources will limit the number of local test jobs to run concurrently instead. Setting this greater than the value for --jobs is ineffectual.]' \
            '--runs_per_test[Specifies number of times to run each test. If any of those attempts fail for any reason, the whole test is considered failed. Normally the value specified is just an integer. Example: --runs_per_test=3 will run all tests 3 times. Alternate syntax: regex_filter@runs_per_test. Where runs_per_test stands for an integer value and regex_filter stands for a list of include and exclude regular expression patterns (Also see -- instrumentation_filter). Example: --runs_per_test=//foo/.*,-//foo/bar/.*@3 runs all tests in //foo/ except those under foo/bar three times. This option can be passed multiple times. The most recently passed argument that matches takes precedence. If nothing matches, the test is only run once.]' \
            '--test_env[Specifies additional environment variables to be injected into the test runner environment. Variables can be either specified by name, in which case its value will be read from the Bazel client environment, or by the name=value pair. This option can be used multiple times to specify several variables. Used only by the '\''bazel test'\'' command.]' \
            '--test_keep_going[When disabled, any non-passing test will cause the entire build to stop. By default all tests are run, even if some do not pass.]' \
            '--test_strategy[Specifies which strategy to use when running tests.]' \
            '--test_timeout[Override the default test timeout values for test timeouts (in secs). If a single positive integer value is specified it will override all categories. If 4 comma-separated integers are specified, they will override the timeouts for short, moderate, long and eternal (in that order). In either form, a value of -1 tells blaze to use its default timeouts for that category.]' \
            '--test_tmpdir[Specifies the base temporary directory for '\''bazel test'\'' to use.]':file:_files \
            '--tvos_simulator_device[The device to simulate when running an tvOS application in the simulator, e. g. '\''Apple TV 1080p'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--tvos_simulator_version[The version of tvOS to run on the simulator when running or testing.]' \
            '--watchos_simulator_device[The device to simulate when running an watchOS application in the simulator, e.g. '\''Apple Watch - 38mm'\''. You can get a list of devices by running '\''xcrun simctl list devicetypes'\'' on the machine the simulator will be run on.]' \
            '--watchos_simulator_version[The version of watchOS to run on the simulator when running or testing.]' \
            '--zip_undeclared_test_outputs[If true, undeclared test outputs will be archived in a zip file.]' \
            '--collapse_duplicate_defines[When enabled, redundant --defines will be removed early in the build. This avoids unnecessary loss of the analysis cache for certain types of equivalent builds.]' \
            '--distinct_host_configuration[Build all the tools used during the build for a distinct configuration from that used for the target program. When this is disabled, the same configuration is used for host and target programs. This may cause undesirable rebuilds of tools such as the protocol compiler (and then everything downstream) whenever a minor change is made to the target configuration, such as setting the linker options. When this is enabled (the default), a distinct configuration will be used to build the tools, preventing undesired rebuilds. However, certain libraries will then need to be compiled twice, once for each configuration, which may cause some builds to be slower. As a rule of thumb, this option is likely to benefit users that make frequent changes in configuration (e.g. opt/dbg). Please read the user manual for the full explanation.]' \
            '--experimental_filter_library_jar_with_program_jar[Filter the ProGuard ProgramJar to remove any classes also present in the LibraryJar.]' \
            '--experimental_inmemory_dotd_files[If enabled, C++ .d files will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_inmemory_jdeps_files[If enabled, the dependency (.jdeps) files generated from Java compilations will be passed through in memory directly from the remote build nodes instead of being written to disk.]' \
            '--experimental_objc_include_scanning[Whether to perform include scanning for objective C/C++.]' \
            '--experimental_parse_headers_skipped_if_corresponding_srcs_found[If enabled, the parse_headers feature does not create a separate header compile action if a source with the same basename is found in the same target.]' \
            '--experimental_retain_test_configuration_across_testonly[When enabled, --trim_test_configuration will not trim the test configuration for rules marked testonly=1. This is meant to reduce action conflict issues when non-test rules depend on cc_test rules. No effect if -- trim_test_configuration is false.]' \
            '--experimental_starlark_cc_import[If enabled, the Starlark version of cc_import can be used.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--incremental_dexing[Does most of the work for dexing separately for each Jar file.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--objc_use_dotd_pruning[If set, .d files emitted by clang will be used to prune the set of inputs passed into objc compiles.]' \
            '--process_headers_in_dependencies[When building a target //a:a, process headers in all targets that //a:a depends on (if header processing is enabled for the toolchain).]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--trim_test_configuration[When enabled, test-related options will be cleared below the top level of the build. When this flag is active, tests cannot be built as dependencies of non-test rules, but changes to test-related options will not cause nontest rules to be re-analyzed.]' \
            '--use_singlejar_apkbuilder[This option is a deprecated. It is now a no-op and will be removed soon.]' \
            '--announce[Deprecated. No-op.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_materialize_param_files_directly[If materializing param files, do so with direct writes to disk.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_repository_resolved_file[If non-empty, write a Starlark value with the resolved information of all Starlark repository rules that were executed.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--explain[Causes the build system to explain each executed step of the build. The explanation is written to the specified log file.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--materialize_param_files[Writes intermediate parameter files to output tree even when using remote action execution. Useful when debugging actions. This is implied by -- subcommands and --verbose_failures.]' \
            '--max_config_changes_to_show[When discarding the analysis cache due to a change in the build options, displays up to the given number of changed option names. If the number given is -1, all changed options will be displayed.]' \
            '--max_test_output_bytes[Specifies maximum per-test-log size that can be emitted when --test_summary is '\''errors'\'' or '\''all'\''. Useful for avoiding overwhelming the output with excessively noisy test output. The test header is included in the log size. Negative values imply no limit. Output is all or nothing.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--output_filter[Only shows warnings for rules with a name matching the provided regular expression.]' \
            '--print_relative_test_log_paths[If true, when printing the path to a test log, use relative path that makes use of the '\''testlogs'\'' convenience symlink. N.B. - A subsequent '\''build'\''/'\''test'\''/etc invocation with a different configuration can cause the target of this symlink to change, making the path printed previously no longer useful.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--progress_report_interval[The number of seconds to wait between two reports on still running jobs. The default value 0 means to use the default 10:30:60 incremental algorithm.]' \
            '--remote_print_execution_messages[Choose when to print remote execution messages. Valid values are `failure`, to print only on failures, `success` to print only on successes and `all` to print always.]' \
            '--show_result[Show the results of the build. For each target, state whether or not it was brought up-to-date, and if so, a list of output files that were built. The printed files are convenient strings for copy+pasting to the shell, to execute them. This option requires an integer argument, which is the threshold number of targets above which result information is not printed. Thus zero causes suppression of the message and MAX_INT causes printing of the result to occur always. The default is one.]' \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--subcommands[Display the subcommands executed during a build.]' \
            '--test_output[Specifies desired output mode. Valid values are '\''summary'\'' to output only test status summary, '\''errors'\'' to also print test logs for failed tests, '\''all'\'' to print logs for all tests and '\''streamed'\'' to output logs for all tests in real time (this will force tests to be executed locally one at a time regardless of --test_strategy value).]' \
            '--test_summary[Specifies the desired format ot the test summary. Valid values are '\''short'\'' to print information only about tests executed, '\''terse'\'', to print information only about unsuccessful tests that were run, '\''detailed'\'' to print detailed information about failed test cases, and '\''none'\'' to omit the summary.]' \
            '--test_verbose_timeout_warnings[If true, print additional warnings when the actual test execution time does not match the timeout defined by the test (whether implied or explicit).]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--toolchain_resolution_debug[Print debug information during toolchain resolution. The flag takes a regex, which is checked against toolchain types and specific targets to see which to debug. Multiple regexes may be separated by commas, and then each regex is checked separately. Note: The output of this flag is very complex and will likely only be useful to experts in toolchain resolution.]':file:_files \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--verbose_explanations[Increases the verbosity of the explanations issued if --explain is enabled. Has no effect if --explain is not enabled.]' \
            '--verbose_failures[If a command fails, print out the full command line.]' \
            '--verbose_test_summary[If true, print additional information (timing, number of failed runs, etc) in the test summary.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--flag_alias[Sets a shorthand name for a Starlark flag. It takes a single key-value pair in the form "<key>=<value>" as an argument.]' \
            '--incompatible_default_to_explicit_init_py[This flag changes the default behavior so that __init__.py files are no longer automatically created in the runfiles of Python targets. Precisely, when a py_binary or py_test target has legacy_create_init set to "auto" (the default), it is treated as false if and only if this flag is set. See https://github.com/bazelbuild/bazel/issues/10076.]' \
            '--incompatible_py2_outputs_are_suffixed[If true, targets built in the Python 2 configuration will appear under an output root that includes the suffix '\''-py2'\'', while targets built for Python 3 will appear in a root with no Python-related suffix. This means that the `bazel-bin` convenience symlink will point to Python 3 targets rather than Python 2. If you enable this option it is also recommended to enable `-- incompatible_py3_is_default`.]' \
            '--incompatible_py3_is_default[If true, `py_binary` and `py_test` targets that do not set their `python_version` (or `default_python_version`) attribute will default to PY3 rather than to PY2. If you set this flag it is also recommended to set `--incompatible_py2_outputs_are_suffixed`.]' \
            '--incompatible_use_python_toolchains[If set to true, executable native Python rules will use the Python runtime specified by the Python toolchain, rather than the runtime given by legacy flags like --python_top.]' \
            '--python_version[The Python major version mode, either `PY2` or `PY3`. Note that this is overridden by `py_binary` and `py_test` targets (even if they don'\''t explicitly specify a version) so there is usually not much reason to supply this flag.]' \
            '--target_pattern_file[If set, build will read patterns from the file named here, rather than on the command line. It is an error to specify a file here as well as commandline patterns.]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--experimental_guard_against_concurrent_changes[Turn this off to disable checking the ctime of input files of an action before uploading it to a remote cache. There may be cases where the Linux kernel delays writing of files, which could cause false positives.]' \
            '--experimental_remote_cache_async[If true, remote cache I/O will happen in the background instead of taking place as the part of a spawn.]' \
            '--experimental_remote_cache_compression[If enabled, compress/decompress cache blobs with zstd.]' \
            '--experimental_remote_capture_corrupted_outputs[A path to a directory where the corrupted outputs will be captured to.]':file:_files \
            '--experimental_remote_downloader[A Remote Asset API endpoint URI, to be used as a remote download proxy. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. See: https://github.com/bazelbuild/remoteapis/blob/master/build/bazel/remote/asset/v1/remote_asset.proto]' \
            '--experimental_remote_execution_keepalive[Whether to use keepalive for remote execution calls.]' \
            '--experimental_remote_grpc_log[If specified, a path to a file to log gRPC call related details. This log consists of a sequence of serialized com.google.devtools.build.lib.remote. logging.RemoteExecutionLog.LogEntry protobufs with each message prefixed by a varint denoting the size of the following serialized protobuf message, as performed by the method LogEntry.writeDelimitedTo(OutputStream).]':file:_files \
            '--experimental_remote_merkle_tree_cache[If set to true, Merkle tree calculations will be memoized to improve the remote cache hit checking speed. The memory foot print of the cache is controlled by --experimental_remote_merkle_tree_cache_size.]' \
            '--experimental_remote_merkle_tree_cache_size[The number of Merkle trees to memoize to improve the remote cache hit checking speed. Even though the cache is automatically pruned according to Java'\''s handling of soft references, out-of-memory errors can occur if set too high. If set to 0 the cache size is unlimited. Optimal value varies depending on project'\''s size. Default to 1000.]' \
            '--incompatible_remote_build_event_upload_respect_no_cache[If set to true, outputs referenced by BEP are not uploaded to remote cache if the generating action cannot be cached remotely.]' \
            '--incompatible_remote_output_paths_relative_to_input_root[If set to true, output paths are relative to input root instead of working directory.]' \
            '--incompatible_remote_results_ignore_disk[If set to true, --noremote_upload_local_results and -- noremote_accept_cached will not apply to the disk cache. If a combined cache is used:]' \
            '--remote_accept_cached[Whether to accept remotely cached action results.]' \
            '--remote_bytestream_uri_prefix[The hostname and instance name to be used in bytestream:// URIs that are written into build event streams. This option can be set when builds are performed using a proxy, which causes the values of --remote_executor and -- remote_instance_name to no longer correspond to the canonical name of the remote execution service. When not set, it will default to "${hostname} /${instance_name}".]' \
            '--remote_cache[A URI of a caching endpoint. The supported schemas are http, https, grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc://, http:// or unix: schema to disable TLS. See https://docs.bazel.build/versions/main/remotecaching.html]' \
            '--remote_cache_header[Specify a header that will be included in cache requests: -- remote_cache_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_default_exec_properties[Set the default exec properties to be used as the remote execution platform if an execution platform does not already set exec_properties.]' \
            '--remote_default_platform_properties[Set the default platform properties to be set for the remote execution API, if the execution platform does not already set remote_execution_properties. This value will also be used if the host platform is selected as the execution platform for remote execution.]' \
            '--remote_downloader_header[Specify a header that will be included in remote downloader requests: -- remote_downloader_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_exec_header[Specify a header that will be included in execution requests: -- remote_exec_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_execution_priority[The relative priority of actions to be executed remotely. The semantics of the particular priority values are server-dependent.]' \
            '--remote_executor[HOST or HOST:PORT of a remote execution endpoint. The supported schemas are grpc, grpcs (grpc with TLS enabled) and unix (local UNIX sockets). If no schema is provided Bazel will default to grpcs. Specify grpc:// or unix: schema to disable TLS.]' \
            '--remote_header[Specify a header that will be included in requests: -- remote_header=Name=Value. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--remote_instance_name[Value to pass as instance_name in the remote execution API.]' \
            '--remote_local_fallback[Whether to fall back to standalone local execution strategy if remote execution fails.]' \
            '--remote_local_fallback_strategy[No-op, deprecated. See https://github.com/bazelbuild/bazel/issues/7480 for details.]' \
            '--remote_max_connections[Limit the max number of concurrent connections to remote cache/executor. By default the value is 100. Setting this to 0 means no limitation. For HTTP remote cache, one TCP connection could handle one request at one time, so Bazel could make up to --remote_max_connections concurrent requests. For gRPC remote cache/executor, one gRPC channel could usually handle 100+ concurrent requests, so Bazel could make around `--remote_max_connections * 100` concurrent requests.]' \
            '--remote_proxy[Connect to the remote cache through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--remote_result_cache_priority[The relative priority of remote actions to be stored in remote cache. The semantics of the particular priority values are server-dependent.]' \
            '--remote_retries[The maximum number of attempts to retry a transient error. If set to 0, retries are disabled.]' \
            '--remote_timeout[The maximum amount of time to wait for remote execution and cache calls. For the REST cache, this is both the connect and the read timeout. Following units can be used: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). If the unit is omitted, the value is interpreted as seconds.]' \
            '--remote_upload_local_results[Whether to upload locally executed action results to the remote cache.]' \
            '--remote_verify_downloads[If set to true, Bazel will compute the hash sum of all remote downloads and discard the remotely cached values if they don'\''t match the expected value.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--auto_output_filter[If --output_filter is not specified, then the value for this option is used create a filter automatically. Allowed values are '\''none'\'' (filter nothing / show everything), '\''all'\'' (filter everything / show nothing), '\''packages'\'' (include output from rules in packages mentioned on the Blaze command line), and '\''subpackages'\'' (like '\''packages'\'', but also include subpackages). For the '\''packages'\'' and '\''subpackages'\'' values //java/foo and //javatests/foo are treated as one package)'\''.]' \
            '--build_manual_tests[Forces test targets tagged '\''manual'\'' to be built. '\''manual'\'' tests are excluded from processing. This option forces them to be built (but not executed).]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--build_tag_filters[Specifies a comma-separated list of tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those targets will be built that contain at least one included tag and do not contain any excluded tags. This option does not affect the set of tests executed with the '\''test'\'' command; those are be governed by the test filtering options, for example '\''--test_tag_filters'\'']' \
            '--build_tests_only[If specified, only *_test and test_suite rules will be built and other targets specified on the command line will be ignored. By default everything that was requested will be built.]' \
            '--cache_test_results[If set to '\''auto'\'', Bazel reruns a test if and only if: (1) Bazel detects changes in the test or its dependencies, (2) the test is marked as external, (3) multiple test runs were requested with --runs_per_test, or(4) the test previously failed. If set to '\''yes'\'', Bazel caches all test results except for tests marked as external. If set to '\''no'\'', Bazel does not cache any test results.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--combined_report[Specifies desired cumulative coverage report type. At this point only LCOV is supported.]' \
            '--compile_one_dependency[Compile a single dependency of the argument files. This is useful for syntax checking source files in IDEs, for example, by rebuilding a single target that depends on the source file to detect errors as early as possible in the edit/build/test cycle. This argument affects the way all non-flag arguments are interpreted; instead of being targets to build they are source filenames. For each source filename an arbitrary target that depends on it will be built.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--deleted_packages[A comma-separated list of names of packages which the build system will consider non-existent, even if they are visible somewhere on the package path. Use this option when deleting a subpackage '\''x/y'\'' of an existing package '\''x'\''. For example, after deleting x/y/BUILD in your client, the build system may complain if it encounters a label '\''//x:y/z'\'' if that is still provided by another package_path entry. Specifying --deleted_packages x/y avoids this problem.]' \
            '--discard_analysis_cache[Discard the analysis cache immediately after the analysis phase completes. Reduces memory usage by ~10%, but makes further incremental builds slower.]' \
            '--disk_cache[A path to a directory where Bazel can read and write actions and action outputs. If the directory does not exist, it will be created.]':file:_files \
            '--embed_label[Embed source control revision or release label in binary]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--execution_log_binary_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--execution_log_json_file[Log the executed spawns into this file as json representation of the delimited Spawn protos.]':file:_files \
            '--expand_test_suites[Expand test_suite targets into their constituent tests before analysis. When this flag is turned on (the default), negative target patterns will apply to the tests belonging to the test suite, otherwise they will not. Turning off this flag is useful when top-level aspects are applied at command line: then they can analyze test_suite targets.]' \
            '--experimental_cancel_concurrent_tests[If true, then Blaze will cancel concurrently running tests on the first successful run. This is only useful in combination with -- runs_per_test_detects_flakes.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_execution_log_file[Log the executed spawns into this file as delimited Spawn protos.]':file:_files \
            '--experimental_extra_action_filter[Deprecated in favor of aspects. Filters set of targets to schedule extra_actions for.]':file:_files \
            '--experimental_extra_action_top_level_only[Deprecated in favor of aspects. Only schedules extra_actions for top level targets.]' \
            '--experimental_fetch_all_coverage_outputs[If true, then Bazel fetches the entire coverage data directory for each test during a coverage run.]' \
            '--experimental_generate_llvm_lcov[If true, coverage for clang will generate an LCOV report.]' \
            '--experimental_j2objc_header_map[Whether to generate J2ObjC header map in parallel of J2ObjC transpilation.]' \
            '--experimental_j2objc_shorter_header_path[Whether to generate with shorter header path (uses "_ios" instead of "_j2objc").]' \
            '--experimental_java_classpath[Enables reduced classpaths for Java compilations.]' \
            '--experimental_limit_android_lint_to_android_constrained_java[Limit --experimental_run_android_lint_on_java_rules to Android-compatible libraries.]' \
            '--experimental_local_execution_delay[How many milliseconds should local execution be delayed, if remote execution was faster during a build at least once?]' \
            '--experimental_local_memory_estimate[Estimate the actual memory available online. By default, Blaze assumes most actions use a fixed amount of memory, and counts that against the total available system memory, regardless of how much memory is actually available. This option enables online estimation of how much memory is available at any given time, and thus does not require accurate estimation of how much memory a given action will take.]' \
            '--experimental_persistent_javac[Enable the experimental persistent Java compiler.]' \
            '--experimental_persistent_test_runner[Allows running java_test targets locally within a persistent worker. To enable the persistent test runner one must run bazel test with the flags:-- test_strategy=local --strategy=TestRunner=worker -- experimental_persistent_test_runner]' \
            '--experimental_run_android_lint_on_java_rules[Whether to validate java_* sources.]' \
            '--experimental_spawn_scheduler[Enable dynamic execution by running actions locally and remotely in parallel. Bazel spawns each action locally and remotely and picks the one that completes first. If an action supports workers, the local action will be run in the persistent worker mode. To enable dynamic execution for an individual action mnemonic, use the `--internal_spawn_scheduler` and `-- strategy=<mnemonic>=dynamic` flags instead.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--experimental_worker_cancellation[If enabled, Bazel may send cancellation requests to workers that support them.]' \
            '--experimental_worker_max_multiplex_instances[How many WorkRequests a multiplex worker process may receive in parallel if you use the '\''worker'\'' strategy with --experimental_worker_multiplex. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*. 5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--experimental_worker_multiplex[If enabled, workers that support the experimental multiplexing feature will use that feature.]' \
            '--explicit_java_test_deps[Explicitly specify a dependency to JUnit or Hamcrest in a java_test instead of accidentally obtaining from the TestRunner'\''s deps. Only works for bazel right now.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--high_priority_workers[Mnemonics of workers to run with high priority. When high priority workers are running all other workers are throttled.]' \
            '--host_java_launcher[The Java launcher used by tools that are executed during a build.]' \
            '--host_javacopt[Additional options to pass to javac when building tools that are executed during a build.]' \
            '--host_jvmopt[Additional options to pass to the Java VM when building tools that are executed during the build. These options will get added to the VM startup options of each java_binary target.]' \
            '--ignore_unsupported_sandboxing[Do not print a warning when sandboxed execution is not supported on this system.]' \
            '--incompatible_dont_use_javasourceinfoprovider[No-op]' \
            '--incompatible_exclusive_test_sandboxed[If true, exclusive tests will run with sandboxed strategy. Add '\''local'\'' tag to force an exclusive test run locally]' \
            '--incompatible_strict_action_env[If true, Bazel uses an environment with a static value for PATH and does not inherit LD_LIBRARY_PATH or TMPDIR. Use --action_env=ENV_VARIABLE if you want to inherit specific environment variables from the client, but note that doing so can prevent cross-user caching if a shared cache is used.]' \
            '--j2objc_translation_flags[Additional options to pass to the J2ObjC tool.]' \
            '--java_debug[Causes the Java virtual machine of a java test to wait for a connection from a JDWP-compliant debugger (such as jdb) before starting the test. Implies -test_output=streamed.]' \
            '--java_deps[Generate dependency information (for now, compile-time classpath) per Java target.]' \
            '--java_header_compilation[Compile ijars directly from source.]' \
            '--java_language_version[The Java language version]' \
            '--java_launcher[The Java launcher to use when building Java binaries. If this flag is set to the empty string, the JDK launcher is used. The "launcher" attribute overrides this flag.]' \
            '--java_runtime_version[The Java runtime version]' \
            '--javacopt[Additional options to pass to javac.]' \
            '--jvmopt[Additional options to pass to the Java VM. These options will get added to the VM startup options of each java_binary target.]' \
            '--legacy_main_dex_list_generator[Specifies a binary to use to generate the list of classes that must be in the main dex when compiling legacy multidex.]' \
            '--local_cpu_resources[Explicitly set the number of local CPU threads available to Bazel. Takes an integer, or "HOST_CPUS", optionally followed by \[-|*\]<float> (eg. HOST_CPUS*.5 to use half the available CPU cores).By default, ("HOST_CPUS"), Bazel will query system configuration to estimate number of CPU cores available for the locally executed build actions. Note: This is a no-op if --local_resources is set.]' \
            '--local_ram_resources[Explicitly set the amount of local host RAM (in MB) available to Bazel. Takes an integer, or "HOST_RAM", optionally followed by \[-|*\]<float> (eg. HOST_RAM*.5 to use half the available RAM).By default, ("HOST_RAM*.67"), Bazel will query system configuration to estimate amount of RAM available for the locally executed build actions and will use 67% of available RAM. Note: This is a no-op if --local_resources is set.]' \
            '--local_termination_grace_seconds[Time to wait between terminating a local process due to timeout and forcefully shutting it down.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--package_path[A colon-separated list of where to look for packages. Elements beginning with '\''%workspace%'\'' are relative to the enclosing workspace. If omitted or empty, the default is the output of '\''bazel info default-package-path'\''.]' \
            '--plugin[Plugins to use in the build. Currently works with java_plugin.]' \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--proguard_top[Specifies which version of ProGuard to use for code removal when building a Java binary.]' \
            '--proto_compiler[The label of the proto-compiler.]' \
            '--proto_toolchain_for_cc[Label of proto_lang_toolchain() which describes how to compile C++ protos]' \
            '--proto_toolchain_for_j2objc[Label of proto_lang_toolchain() which describes how to compile j2objc protos]' \
            '--proto_toolchain_for_java[Label of proto_lang_toolchain() which describes how to compile Java protos]' \
            '--proto_toolchain_for_javalite[Label of proto_lang_toolchain() which describes how to compile JavaLite protos]' \
            '--protocopt[Additional options to pass to the protobuf compiler.]' \
            '--runs_per_test_detects_flakes[If true, any shard in which at least one run/attempt passes and at least one run/attempt fails gets a FLAKY status.]' \
            '--sandbox_add_mount_pair[Add additional path pair to mount in sandbox.]':file:_files \
            '--sandbox_base[Lets the sandbox create its sandbox directories underneath this path. Specify a path on tmpfs (like /run/shm) to possibly improve performance a lot when your build / tests have many input files. Note: You need enough RAM and free space on the tmpfs to hold output and intermediate files generated by running actions.]' \
            '--sandbox_block_path[For sandboxed actions, disallow access to this path.]' \
            '--sandbox_debug[Enables debugging features for the sandboxing feature. This includes two things: first, the sandbox root contents are left untouched after a build (and if sandboxfs is in use, the file system is left mounted); and second, prints extra debugging information on execution. This can help developers of Bazel or Starlark rules with debugging failures due to missing input files, etc.]' \
            '--sandbox_default_allow_network[Allow network access by default for actions; this may not work with all sandboxing implementations.]' \
            '--sandbox_fake_hostname[Change the current hostname to '\''localhost'\'' for sandboxed actions.]' \
            '--sandbox_fake_username[Change the current username to '\''nobody'\'' for sandboxed actions.]' \
            '--sandbox_tmpfs_path[For sandboxed actions, mount an empty, writable directory at this absolute path (if supported by the sandboxing implementation, ignored otherwise).]':file:_files \
            '--sandbox_writable_path[For sandboxed actions, make an existing directory writable in the sandbox (if supported by the sandboxing implementation, ignored otherwise).]' \
            '--shell_executable[Absolute path to the shell executable for Bazel to use. If this is unset, but the BAZEL_SH environment variable is set on the first Bazel invocation (that starts up a Bazel server), Bazel uses that. If neither is set, Bazel uses a hard-coded default path depending on the operating system it runs on (Windows: c:/tools/msys64/usr/bin/bash.exe, FreeBSD: /usr/local/bin/bash, all others: /bin/bash). Note that using a shell that is not compatible with bash may lead to build failures or runtime failures of the generated binaries.]':file:_files \
            '--show_loading_progress[If enabled, causes Bazel to print "Loading package:" messages.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--test_arg[Specifies additional options and arguments that should be passed to the test executable. Can be used multiple times to specify several arguments. If multiple tests are executed, each of them will receive identical arguments. Used only by the '\''bazel test'\'' command.]' \
            '--test_filter[Specifies a filter to forward to the test framework. Used to limit the tests run. Note that this does not affect which targets are built.]' \
            '--test_lang_filters[Specifies a comma-separated list of test languages. Each language can be optionally preceded with '\''-'\'' to specify excluded languages. Only those test targets will be found that are written in the specified languages. The name used for each language should be the same as the language prefix in the *_test rule, e.g. one of '\''cc'\'', '\''java'\'', '\''py'\'', etc. This option affects -- build_tests_only behavior and the test command.]' \
            '--test_result_expiration[This option is deprecated and has no effect.]' \
            '--test_runner_fail_fast[Forwards fail fast option to the test runner. The test runner should stop execution upon first failure.]' \
            '--test_sharding_strategy[Specify strategy for test sharding: '\''explicit'\'' to only use sharding if the '\''shard_count'\'' BUILD attribute is present. '\''disabled'\'' to never use test sharding.]' \
            '--test_size_filters[Specifies a comma-separated list of test sizes. Each size can be optionally preceded with '\''-'\'' to specify excluded sizes. Only those test targets will be found that contain at least one included size and do not contain any excluded sizes. This option affects --build_tests_only behavior and the test command.]' \
            '--test_tag_filters[Specifies a comma-separated list of test tags. Each tag can be optionally preceded with '\''-'\'' to specify excluded tags. Only those test targets will be found that contain at least one included tag and do not contain any excluded tags. This option affects --build_tests_only behavior and the test command.]' \
            '--test_timeout_filters[Specifies a comma-separated list of test timeouts. Each timeout can be optionally preceded with '\''-'\'' to specify excluded timeouts. Only those test targets will be found that contain at least one included timeout and do not contain any excluded timeouts. This option affects --build_tests_only behavior and the test command.]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--tool_java_language_version[The Java language version used to execute the tools that are needed during a build]' \
            '--tool_java_runtime_version[The Java runtime version used to execute tools during the build]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--use_ijars[If enabled, this option causes Java compilation to use interface jars. This will result in faster incremental compilation, but error messages can be different.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            '--worker_extra_flag[Extra command-flags that will be passed to worker processes in addition to --persistent_worker, keyed by mnemonic (e.g. --worker_extra_flag=Javac=-- debug.]' \
            '--worker_max_instances[How many instances of a worker process (like the persistent Java compiler) may be launched if you use the '\''worker'\'' strategy. May be specified as \[name=value\] to give a different value per worker mnemonic. Takes an integer, or a keyword ("auto", "HOST_CPUS", "HOST_RAM"), optionally followed by an operation (\[-|*\]<float>) eg. "auto", "HOST_CPUS*.5". '\''auto'\'' calculates a reasonable default based on machine capacity. "=value" sets a default for unspecified mnemonics.]' \
            '--worker_quit_after_build[If enabled, all workers quit after a build is done.]' \
            '--worker_sandboxing[If enabled, workers will be executed in a sandboxed environment.]' \
            '--worker_verbose[If enabled, prints verbose messages when workers are started, shutdown, ...]' \
            '--workspace_status_command[A command invoked at the beginning of the build to provide status information about the workspace in the form of key/value pairs. See the User'\''s Manual for the full specification. Also see tools/buildstamp/get_workspace_status for an example.]':file:_files \
            "*: :_files"

    }

    function _bazel_version {
        _arguments \
            '--check_direct_dependencies[Check if the direct `bazel_dep` dependencies declared in the root module are the same versions you get in the resolved dependency graph. Valid values are `off` to disable the check, `warning` to print a warning when mismatch detected or `error` to escalate it to a resolution failure.]' \
            '--distdir[Additional places to search for archives before accessing the network to download them.]':file:_files \
            '--experimental_enable_bzlmod[If true, Bazel tries to load external repositories from the Bzlmod system before looking into the WORKSPACE file.]' \
            '--experimental_repository_cache_hardlinks[If set, the repository cache will hardlink the file in case of a cache hit, rather than copying. This is intended to save disk space.]' \
            '--experimental_repository_cache_urls_as_default_canonical_id[If true, use a string derived from the URLs of repository downloads as the canonical_id if not specified. This causes a change in the URLs to result in a redownload even if the cache contains a download with the same hash. This can be used to verify that URL changes don'\''t result in broken repositories being masked by the cache.]' \
            '--experimental_repository_disable_download[If set, downloading external repositories is not allowed.]' \
            '--experimental_repository_downloader_retries[The maximum number of attempts to retry a download error. If set to 0, retries are disabled.]' \
            '--experimental_scale_timeouts[Scale all timeouts in Starlark repository rules by this factor. In this way, external repositories can be made working on machines that are slower than the rule author expected, without changing the source code]' \
            '--http_timeout_scaling[Scale all timeouts related to http downloads by the given factor]' \
            '--ignore_dev_dependency[If true, Bazel ignores `bazel_dep` and `use_extension` declared as `dev_dependency` in the MODULE.bazel of the root module. Note that, those dev dependencies are always ignored in the MODULE.bazel if it'\''s not the root module regardless of the value of this flag.]' \
            '--registry[Specifies the registries to use to locate Bazel module dependencies. The order is important: modules will be looked up in earlier registries first, and only fall back to later registries when they'\''re missing from the earlier ones.]' \
            '--repository_cache[Specifies the cache location of the downloaded values obtained during the fetching of external repositories. An empty string as argument requests the cache to be disabled.]':file:_files \
            '--experimental_oom_more_eagerly_threshold[If this flag is set to a value less than 100, Bazel will OOM if, after two full GC'\''s, more than this percentage of the (old gen) heap is still occupied.]' \
            '--experimental_ui_max_stdouterr_bytes[The maximum size of the stdout / stderr files that will be printed to the console. -1 implies no limit.]' \
            '--gnu_format[If set, write the version to stdout using the conventions described in the GNU standards.]' \
            '--repo_env[Specifies additional environment variables to be available only for repository rules. Note that repository rules see the full environment anyway, but in this way configuration information can be passed to repositories through options without invalidating the action graph.]' \
            '--experimental_repository_hash_file[If non-empty, specifies a file containing a resolved value, against which the repository directory hashes should be verified]' \
            '--experimental_verify_repository_rules[If list of repository rules for which the hash of the output directory should be verified, provided a file is specified by -- experimental_repository_hash_file.]' \
            '--experimental_action_resource_set[If set to true, ctx.actions.run() and ctx.actions.run_shell() accept a resource_set parameter for local execution. Otherwise it will default to 250 MB for memory and 1 cpu.]' \
            '--experimental_allow_tags_propagation[If set to true, tags will be propagated from a target to the actions'\'' execution requirements; otherwise tags are not propagated. See https: //github.com/bazelbuild/bazel/issues/8830 for details.]' \
            '--experimental_analysis_test_call[If set to true, analysis_test native call is available.]' \
            '--experimental_cc_shared_library[If set to true, rule attributes and Starlark API methods needed for the rule cc_shared_library will be available]' \
            '--experimental_disable_external_package[If set to true, the auto-generated //external package will not be available anymore. Bazel will still be unable to parse the file '\''external/BUILD'\'', but globs reaching into external/ from the unnamed package will work.]' \
            '--experimental_enable_android_migration_apis[If set to true, enables the APIs required to support the Android Starlark migration.]' \
            '--experimental_google_legacy_api[If set to true, exposes a number of experimental pieces of Starlark build API pertaining to Google legacy code.]' \
            '--experimental_ninja_actions[If set to true, enables Ninja execution functionality.]' \
            '--experimental_platforms_api[If set to true, enables a number of platform-related Starlark APIs useful for debugging.]' \
            '--experimental_repo_remote_exec[If set to true, repository_rule gains some remote execution capabilities.]' \
            '--experimental_sibling_repository_layout[If set to true, non-main repositories are planted as symlinks to the main repository in the execution root. That is, all repositories are direct children of the $output_base/execution_root directory. This has the side effect of freeing up $output_base/execution_root/__main__/external for the real top-level '\''external'\'' directory.]' \
            '--incompatible_always_check_depset_elements[Check the validity of elements added to depsets, in all constructors. Elements must be immutable, but historically the depset(direct=...) constructor forgot to check. Use tuples instead of lists in depset elements. See https://github.com/bazelbuild/bazel/issues/10313 for details.]' \
            '--incompatible_depset_for_libraries_to_link_getter[When true, Bazel no longer returns a list from linking_context. libraries_to_link but returns a depset instead.]' \
            '--incompatible_disable_depset_items[If set to true, disable the '\''items'\'' parameter of the depset constructor. Use the '\''transitive'\'' and '\''direct'\'' parameters instead.]' \
            '--incompatible_disable_target_provider_fields[If set to true, disable the ability to access providers on '\''target'\'' objects via field syntax. Use provider-key syntax instead. For example, instead of using `ctx.attr.dep.my_info` to access `my_info` from inside a rule implementation function, use `ctx.attr.dep\[MyInfo\]`. See https://github. com/bazelbuild/bazel/issues/9014 for details.]' \
            '--incompatible_disable_third_party_license_checking[If true, disables all license checking logic]' \
            '--incompatible_disallow_empty_glob[If set to true, the default value of the `allow_empty` argument of glob() is False.]' \
            '--incompatible_disallow_legacy_javainfo[Deprecated. No-op.]' \
            '--incompatible_disallow_struct_provider_syntax[If set to true, rule implementation functions may not return a struct. They must instead return a list of provider instances.]' \
            '--incompatible_enable_exports_provider[This flag enables exports provider and JavaInfo.transitive_exports call.]' \
            '--incompatible_existing_rules_immutable_view[If set to true, native.existing_rule and native.existing_rules return lightweight immutable view objects instead of mutable dicts.]' \
            '--incompatible_java_common_parameters[If set to true, the output_jar, and host_javabase parameters in pack_sources and host_javabase in compile will all be removed.]' \
            '--incompatible_linkopts_to_linklibs[If set to true the default linkopts in the default toolchain are passed as linklibs instead of linkopts to cc_toolchain_config]' \
            '--incompatible_new_actions_api[If set to true, the API to create actions is only available on `ctx. actions`, not on `ctx`.]' \
            '--incompatible_no_attr_license[If set to true, disables the function `attr.license`.]' \
            '--incompatible_no_implicit_file_export[If set, (used) source files are are package private unless exported explicitly. See https://github. com/bazelbuild/proposals/blob/master/designs/2019-10-24-file-visibility.md]' \
            '--incompatible_no_rule_outputs_param[If set to true, disables the `outputs` parameter of the `rule()` Starlark function.]' \
            '--incompatible_require_linker_input_cc_api[If set to true, rule create_linking_context will require linker_inputs instead of libraries_to_link. The old getters of linking_context will also be disabled and just linker_inputs will be available.]' \
            '--incompatible_run_shell_command_string[If set to true, the command parameter of actions.run_shell will only accept string]' \
            '--incompatible_struct_has_no_methods[Disables the to_json and to_proto methods of struct, which pollute the struct field namespace. Instead, use json.encode or json.encode_indent for JSON, or proto.encode_text for textproto.]' \
            '--incompatible_top_level_aspects_require_providers[If set to true, the top level aspect will honor its required providers and only run on top level targets whose rules'\'' advertised providers satisfy the required providers of the aspect.]' \
            '--incompatible_use_cc_configure_from_rules_cc[When true, Bazel will no longer allow using cc_configure from @bazel_tools. Please see https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.]' \
            '--incompatible_visibility_private_attributes_at_definition[If set to true, the visibility of private rule attributes is checked with respect to the rule definition, rather than the rule usage.]' \
            '--max_computation_steps[The maximum number of Starlark computation steps that may be executed by a BUILD file (zero means no limit).]' \
            '--nested_set_depth_limit[The maximum depth of the graph internal to a depset (also known as NestedSet), above which the depset() constructor will fail.]' \
            '--incompatible_do_not_split_linking_cmdline[When true, Bazel no longer modifies command line flags used for linking, and also doesn'\''t selectively decide which flags go to the param file and which don'\''t. See https://github.com/bazelbuild/bazel/issues/7670 for details.]' \
            '--keep_state_after_build[If false, Blaze will discard the inmemory state from this build when the build finishes. Subsequent builds will not have any incrementality with respect to this one.]' \
            '--track_incremental_state[If false, Blaze will not persist data that allows for invalidation and reevaluation on incremental builds in order to save memory on this build. Subsequent builds will not have any incrementality with respect to this one. Usually you will want to specify --batch when setting this to false.]' \
            '--announce_rc[Whether to announce rc options.]' \
            '--attempt_to_print_relative_paths[When printing the location part of messages, attempt to use a path relative to the workspace directory or one of the directories specified by -- package_path.]' \
            '--bes_backend[Specifies the build event service (BES) backend endpoint in the form \[SCHEME://\]HOST\[:PORT\]. The default is to disable BES uploads. Supported schemes are grpc and grpcs (grpc with TLS enabled). If no scheme is provided, Bazel assumes grpcs.]' \
            '--bes_header[Specify a header in NAME=VALUE form that will be included in BES requests. Multiple headers can be passed by specifying the flag multiple times. Multiple values for the same name will be converted to a comma-separated list.]' \
            '--bes_instance_name[Specifies the instance name under which the BES will persist uploaded BEP. Defaults to null.]' \
            '--bes_keywords[Specifies a list of notification keywords to be added the default set of keywords published to BES ("command_name=<command_name> ", "protocol_name=BEP"). Defaults to none.]' \
            '--bes_lifecycle_events[Specifies whether to publish BES lifecycle events. (defaults to '\''true'\'').]' \
            '--bes_outerr_buffer_size[Specifies the maximal size of stdout or stderr to be buffered in BEP, before it is reported as a progress event. Individual writes are still reported in a single event, even if larger than the specified value up to -- bes_outerr_chunk_size.]' \
            '--bes_outerr_chunk_size[Specifies the maximal size of stdout or stderr to be sent to BEP in a single message.]' \
            '--bes_proxy[Connect to the Build Event Service through a proxy. Currently this flag can only be used to configure a Unix domain socket (unix:/path/to/socket).]' \
            '--bes_results_url[Specifies the base URL where a user can view the information streamed to the BES backend. Bazel will output the URL appended by the invocation id to the terminal.]' \
            '--bes_timeout[Specifies how long bazel should wait for the BES/BEP upload to complete after the build and tests have finished. A valid timeout is a natural number followed by a unit: Days (d), hours (h), minutes (m), seconds (s), and milliseconds (ms). The default value is '\''0'\'' which means that there is no timeout.]' \
            '--build_event_binary_file[If non-empty, write a varint delimited binary representation of representation of the build event protocol to that file. This option implies --bes_upload_mode=wait_for_upload_complete.]' \
            '--build_event_binary_file_path_conversion[Convert paths in the binary file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_json_file[If non-empty, write a JSON serialisation of the build event protocol to that file.]' \
            '--build_event_json_file_path_conversion[Convert paths in the json file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--build_event_max_named_set_of_file_entries[The maximum number of entries for a single named_set_of_files event; values smaller than 2 are ignored and no event splitting is performed. This is intended for limiting the maximum event size in the build event protocol, although it does not directly control event size. The total event size is a function of the structure of the set as well as the file and uri lengths, which may in turn depend on the hash function.]' \
            '--build_event_publish_all_actions[Whether all actions should be published.]' \
            '--build_event_text_file[If non-empty, write a textual representation of the build event protocol to that file]' \
            '--build_event_text_file_path_conversion[Convert paths in the text file representation of the build event protocol to more globally valid URIs whenever possible; if disabled, the file:// uri scheme will always be used]' \
            '--experimental_announce_profile_path[If enabled, adds the JSON profile path to the log.]' \
            '--experimental_bep_target_summary[Whether to publish TargetSummary events.]' \
            '--experimental_build_event_expand_filesets[If true, expand Filesets in the BEP when presenting output files.]' \
            '--experimental_build_event_fully_resolve_fileset_symlinks[If true, fully resolve relative Fileset symlinks in the BEP when presenting output files. Requires --experimental_build_event_expand_filesets.]' \
            '--experimental_build_event_upload_strategy[Selects how to upload artifacts referenced in the build event protocol.]' \
            '--experimental_profile_additional_tasks[Specifies additional profile tasks to be included in the profile.]':file:_files \
            '--experimental_profile_include_primary_output[Includes the extra "out" attribute in action events that contains the exec path to the action'\''s primary output.]' \
            '--experimental_profile_include_target_label[Includes target label in action events'\'' JSON profile data.]' \
            '--experimental_record_metrics_for_all_mnemonics[By default the number of action types is limited to the 20 mnemonics with the largest number of executed actions. Setting this option will write statistics for all mnemonics.]' \
            '--experimental_stream_log_file_uploads[Stream log file uploads directly to the remote storage rather than writing them to disk.]' \
            '--experimental_workspace_rules_log_file[Log certain Workspace Rules events into this file as delimited WorkspaceEvent protos.]':file:_files \
            '--generate_json_trace_profile[If enabled, Bazel profiles the build and writes a JSON-format profile into a file in the output base. View profile by loading into chrome://tracing. By default Bazel writes the profile for all build-like commands and query.]' \
            '--heap_dump_on_oom[Whether to manually output a heap dump if an OOM is thrown (including OOMs due to --experimental_oom_more_eagerly_threshold). The dump will be written to <output_base>/<invocation_id>.heapdump.hprof. This option effectively replaces -XX:+HeapDumpOnOutOfMemoryError, which has no effect because OOMs are caught and redirected to Runtime#halt.]' \
            '--legacy_important_outputs[Use this to suppress generation of the legacy important_outputs field in the TargetComplete event.]' \
            '--logging[The logging level.]' \
            '--memory_profile_stable_heap_parameters[Tune memory profile'\''s computation of stable heap at end of build. Should be two integers separated by a comma. First parameter is the number of GCs to perform. Second parameter is the number of seconds to wait between GCs.]' \
            '--profile[If set, profile Bazel and write data to the specified file. Use bazel analyze-profile to analyze the profile.]':file:_files \
            '--slim_profile[Slims down the size of the JSON profile by merging events if the profile gets too large.]' \
            '--starlark_cpu_profile[Writes into the specified file a pprof profile of CPU usage by all Starlark threads.]' \
            '--tool_tag[A tool name to attribute this Bazel invocation to.]' \
            '--ui_event_filters[Specifies which events to show in the UI. It is possible to add or remove events to the default ones using leading +/-, or override the default set completely with direct assignment. The set of supported event kinds include INFO, DEBUG, ERROR and more.]' \
            '--experimental_resolved_file_instead_of_workspace[If non-empty read the specified resolved file instead of the WORKSPACE file]' \
            '--experimental_downloader_config[Specify a file to configure the remote downloader with. This file consists of lines, each of which starts with a directive (`allow`, `block` or `rewrite`) followed by either a host name (for `allow` and `block`) or two patterns, one to match against, and one to use as a substitute URL, with back-references starting from `$1`. It is possible for multiple `rewrite` directives for the same URL to be give, and in this case multiple URLs will be returned.]' \
            '--all_incompatible_changes[No-op, being removed. See https://github.com/bazelbuild/bazel/issues/13892]' \
            '--build_metadata[Custom key-value string pairs to supply in a build event.]' \
            '--color[Use terminal controls to colorize output.]' \
            '--config[Selects additional config sections from the rc files; for every <command>, it also pulls in the options from <command>:<config> if such a section exists; if this section doesn'\''t exist in any .rc file, Blaze fails with an error. The config sections and flag combinations they are equivalent to are located in the tools/*.blazerc config files.]' \
            '--curses[Use terminal cursor controls to minimize scrolling output.]' \
            '--enable_platform_specific_config[If true, Bazel picks up host-OS-specific config lines from bazelrc files. For example, if the host OS is Linux and you run bazel build, Bazel picks up lines starting with build:linux. Supported OS identifiers are linux, macos, windows, freebsd, and openbsd. Enabling this flag is equivalent to using --config=linux on Linux, --config=windows on Windows, etc.]' \
            '--experimental_credential_helper[Configures Credential Helpers to use for retrieving credentials for the provided scope (domain).]':file:_files \
            '--experimental_credential_helper_cache_duration[Configures the duration for which credentials from Credential Helpers are cached.]' \
            '--experimental_credential_helper_timeout[Configures the timeout for the Credential Helper.]' \
            '--experimental_windows_watchfs[If true, experimental Windows support for --watchfs is enabled. Otherwise -- watchfsis a non-op on Windows. Make sure to also enable --watchfs.]' \
            '--google_auth_scopes[A comma-separated list of Google Cloud authentication scopes.]' \
            '--google_credentials[Specifies the file to get authentication credentials from. See https: //cloud.google.com/docs/authentication for details.]' \
            '--google_default_credentials[Whether to use '\''Google Application Default Credentials'\'' for authentication. See https://cloud.google.com/docs/authentication for details. Disabled by default.]' \
            '--grpc_keepalive_time[Configures keep-alive pings for outgoing gRPC connections. If this is set, then Bazel sends pings after this much time of no read operations on the connection, but only if there is at least one pending gRPC call. Times are treated as second granularity; it is an error to set a value less than one second. By default, keep-alive pings are disabled. You should coordinate with the service owner before enabling this setting.]' \
            '--grpc_keepalive_timeout[Configures a keep-alive timeout for outgoing gRPC connections. If keepalive pings are enabled with --grpc_keepalive_time, then Bazel times out a connection if it does not receive a ping reply after this much time. Times are treated as second granularity; it is an error to set a value less than one second. If keep-alive pings are disabled, then this setting is ignored.]' \
            '--override_repository[Overrides a repository with a local directory.]':file:_files \
            '--progress_in_terminal_title[Show the command progress in the terminal title. Useful to see what bazel is doing when having multiple terminal tabs.]' \
            '--show_progress[Display progress messages during a build.]' \
            '--show_progress_rate_limit[Minimum number of seconds between progress messages in the output.]' \
            '--show_task_finish[Display progress messages when tasks complete, not just when they start.]' \
            '--show_timestamps[Include timestamps in messages]' \
            '--tls_certificate[Specify a path to a TLS certificate that is trusted to sign server certificates.]' \
            '--tls_client_certificate[Specify the TLS client certificate to use; you also need to provide a client key to enable client authentication.]' \
            '--tls_client_key[Specify the TLS client key to use; you also need to provide a client certificate to enable client authentication.]' \
            '--ui_actions_shown[Number of concurrent actions shown in the detailed progress bar; each action is shown on a separate line. The progress bar always shows at least one one, all numbers less than 1 are mapped to 1.]' \
            '--watchfs[On Linux/macOS: If true, bazel tries to use the operating system'\''s file watch service for local changes instead of scanning every file for a change. On Windows: this flag currently is a non-op but can be enabled in conjunction with --experimental_windows_watchfs. On any OS: The behavior is undefined if your workspace is on a network file system, and files are edited on a remote machine.]' \
            "*: :_files"

    }


function _bazel {
    local line state

    function _commands {
        local -a commands
        commands=(
            'analyze-profile:Analyzes build profile data.'
            'aquery:Analyzes the given targets and queries the action graph.'
            'build:Builds the specified targets.'
            'canonicalize-flags:Canonicalizes a list of bazel options.'
            'clean:Removes output files and optionally stops the server.'
            'coverage:Generates code coverage report for specified test targets.'
            'cquery:Loads, analyzes, and queries the specified targets w/ configurations.'
            'dump:Dumps the internal state of the bazel server process.'
            'fetch:Fetches external repositories that are prerequisites to the targets.'
            'help:Prints help for commands, or the index.'
            'info:Displays runtime info about the bazel server.'
            'license:Prints the license of this software.'
            'mobile-install:Installs targets to mobile devices.'
            'print_action:Prints the command line args for compiling a file.'
            'query:Executes a dependency graph query.'
            'run:Runs the specified target.'
            'shutdown:Stops the bazel server.'
            'sync:Syncs all repositories specified in the workspace file'
            'test:Builds and runs the specified test targets.'
            'version:Prints version information for bazel.'
        )
        _describe 'command' commands
    }
 

    _arguments -C \
        ': :->cmd' \
        '*:: :->subcmd'

    case $state in
    (cmd)
        _commands
        ;;
    (subcmd)
        case $line[1] in
        (analyze-profile)
            _bazel_analyze-profile
            ;;

        (aquery)
            _bazel_aquery
            ;;

        (build)
            _bazel_build
            ;;

        (canonicalize-flags)
            _bazel_canonicalize-flags
            ;;

        (clean)
            _bazel_clean
            ;;

        (coverage)
            _bazel_coverage
            ;;

        (cquery)
            _bazel_cquery
            ;;

        (dump)
            _bazel_dump
            ;;

        (fetch)
            _bazel_fetch
            ;;

        (help)
            _bazel_help
            ;;

        (info)
            _bazel_info
            ;;

        (license)
            _bazel_license
            ;;

        (mobile-install)
            _bazel_mobile-install
            ;;

        (print_action)
            _bazel_print_action
            ;;

        (query)
            _bazel_query
            ;;

        (run)
            _bazel_run
            ;;

        (shutdown)
            _bazel_shutdown
            ;;

        (sync)
            _bazel_sync
            ;;

        (test)
            _bazel_test
            ;;

        (version)
            _bazel_version
            ;;

        esac
        ;;
     esac

}

